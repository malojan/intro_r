[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to R",
    "section": "",
    "text": "1 Preface\nThis is an introduction to programming with R and Rstudio designed for political science students with no programming experience. The aim of the course is to demonstrate the value of programming in a social science context, so that by the end of the course, students will be keen to delve deeper, since the content here will necessarily be limited.\nhttps://jhudatascience.org/tidyversecourse/intro.html#the-here-package"
  },
  {
    "objectID": "01_getting_started.html#goals-of-the-class",
    "href": "01_getting_started.html#goals-of-the-class",
    "title": "Introduction",
    "section": "Goals of the class",
    "text": "Goals of the class\n\nApply\nGiving you the will to continue and to apply\nStudy variations and relationship with statistics"
  },
  {
    "objectID": "01_getting_started.html#evaluation",
    "href": "01_getting_started.html#evaluation",
    "title": "Introduction",
    "section": "Evaluation",
    "text": "Evaluation\nTo learn R, you have to practice. And this is why the evaluation will be based on regular exercises :\n\nEach one will be graded on 5points which will give you a note of 20 at the end of the semester"
  },
  {
    "objectID": "01_getting_started.html#why-programming-and-why-r",
    "href": "01_getting_started.html#why-programming-and-why-r",
    "title": "2  Introduction",
    "section": "2.3 Why programming and why R",
    "text": "2.3 Why programming and why R\nTo analyze quantitative data, we need a computer to help us to do some tasks such as accessing, manipulating data, vizualizing it and modelling it. To ask our computer to do it, we usaully rely on a software and there are of different kind in the market. You probably all know excel or you would have heard of STATA, SPSS or SAS. However, the trend is to use R and has becoming more and more popular.\n\nMost important tools : other programming languages like Python. But R : wonderful langague, really excited to introducign to you\nIt s free : built by a community of people, people adapt the language to new tools\n\nYou might be thinking, “I’ve already learned Excel and can perform some data analysis tasks with it. Why should I bother learning to code in a seemingly complex language?”\nHowever, this has the disadvantage of having less comprehensive documentation compared to other languages like STATA.\n\nWhy to learn how program ? What is it by the way ?\nImportance of reproducibility, replication crisis\n\nNowadays, if you want to publish in a journal using quantitative data, almost all of them will ask your for your replication code.\nRegarding your future career, there are also a lot of incentives to learn R : 1. Jobs 2. Publishing : - Replicate, give track on what you have done.\nIn you want to continue in academia, quantitative skills and programming are highly valuable and pre-requisite for many positions. Journals also more and more ask for replications code when you want to publish an article in order that the other could replicate your findings. In political science, R is more and more the dominant language.\nFurthermore, and I want to insist on that, even if you think you are mostly a qualitative researcher, learning how to programm might be useful. You need to distinguish between data collection and data analysis. For instance, you might want to do qualitative interview with people or studying documents and archives but then developing a textual analysis of your interview to discover some patterns. You might also want to analysis qualitatively a lot of documents/text/reports but getting them from internet in the good format might be tedious and programming might be helpful for this : you might want to archive data, to download directly from the internet.\nEven if you want to pursue a career in an other sector, “data science” skills are also really valuable.\n\nWhy not Python ? Python also highly valuable skills and more popular in industry in general. Moreover, if you are interested in recent machine learning techniques and text analysis, everything that is developed is in Python. Python is more general, more flexible because less abstraction"
  },
  {
    "objectID": "01_getting_started.html#why-r-and-rstudio",
    "href": "01_getting_started.html#why-r-and-rstudio",
    "title": "2  Introduction",
    "section": "2.5 Why R and Rstudio ?",
    "text": "2.5 Why R and Rstudio ?\n\nRise of computational social sciences : if you want to know more about this : have a look on Why learn R ? Why should we bother.\nSpecialized in statistics\nFree and open source, large community\nBut high learning curve : learning R is quite difficult at the begining. And the best thing to do to learn it is to have a goal.\n\nTo start this course and programming, you need several things"
  },
  {
    "objectID": "01_getting_started.html#how-rstudio-is-organized",
    "href": "01_getting_started.html#how-rstudio-is-organized",
    "title": "2  Introduction",
    "section": "2.4 How Rstudio is organized",
    "text": "2.4 How Rstudio is organized\nRStudio is an integrated development environment (IDE) for R. It provides a user-friendly interface for working with R, and includes features such as a code editor, a console for executing R code, a data viewer, and tools for debugging and profiling R code. RStudio also supports the creation of interactive documents and web applications using Quarto or RMarkdown, which allows users to combine code, text, and graphics into a single document.\n\nScript/open files : might be a presentation, a website, a R script, a Quarto document and so on. Code windows, things we want to save and re-run later. SAVE AS script. MAC should be at the Home directory.\nConsole : where the output of your code will appear\nEnvironment : all of the objects we have saved in Rstudio. lean new objects, assignments.\nWorking directory : place in our computer where R will read ans save file, usually default, but this is really important, it is where your files leave in your computer\nWhat is a working directory : where is my file living on my computer"
  },
  {
    "objectID": "01_getting_started.html#quarto-markdown-and-plain-text",
    "href": "01_getting_started.html#quarto-markdown-and-plain-text",
    "title": "2  Introduction",
    "section": "2.11 Quarto, markdown and plain text",
    "text": "2.11 Quarto, markdown and plain text\nI already told you about replication and eveyrhing. Rstudio allows you to combine text and code in the same documents. I will try to introduce you to these tools because there are really nice to write.\n\nScript : way to write down code, you do not have to write everything again next time\n\n\n2.11.1 Basic code\n\nDo some vocab definitions ? What is a function ? What is a vector ?\nObjects and assignments in R <- However, we use scripts in R\nWhat is a function, what is an argument\nLearn how to use a script to compute different things\n\nWe will work with the code editor, you can write script.\nFirst, R can be used as a calculator to perform different operations.\n\n2*3\n\n[1] 6\n\n2/6\n\n[1] 0.3333333\n\n\n\nR script : write code and # with comments\nOr literate programming documents : Quarto/Rmarkdown : documents that allows you to combine text and code and then to convert them in pdf, word or html format."
  },
  {
    "objectID": "01_getting_started.html#r-projects-and-path",
    "href": "01_getting_started.html#r-projects-and-path",
    "title": "2  Introduction",
    "section": "2.5 R “projects” and path",
    "text": "2.5 R “projects” and path\n\nPath, set working directory\nR projects\nHow your computer is organized.\nRecommend do not save your workspace\n\n\n2.5.1 Basic code\nFirst, R can be used as a calculator to perform different operations, either in a script or directly in the console. The output will be generated in the console each time you run one line of code (CTRL + Enter)\n\n3*9*10\n\n[1] 270\n\n2/6\n\n[1] 0.3333333\n\n2^2\n\n[1] 4"
  },
  {
    "objectID": "01_getting_started.html#packages-and-libraries",
    "href": "01_getting_started.html#packages-and-libraries",
    "title": "2  Introduction",
    "section": "2.11 Packages and libraries",
    "text": "2.11 Packages and libraries\n\nWhat is a package : you must use quotation marks you must use (single or double) quotation marks around the package’s name:\nCalling a package"
  },
  {
    "objectID": "01_getting_started.html#setting-preferences",
    "href": "01_getting_started.html#setting-preferences",
    "title": "2  Introduction",
    "section": "2.9 Setting preferences",
    "text": "2.9 Setting preferences\n\nRecommand you to remove this and this\nScript : way to write down code, you do not have to write everything again next time\n\n\n2.9.1 Basic code\n\nDo some vocab definitions ? What is a function ? What is a vector ?\nObjects and assignments in R <- However, we use scripts in R\nWhat is a function, what is an argument\nLearn how to use a script to compute different things\n\nWe will work with the code editor, you can write script, you can do basic calculations and see the result in the console\n\n2*3\n\n[1] 6\n\n2/6\n\n[1] 0.3333333\n\n\n\nWhat is an object, what is the environment"
  },
  {
    "objectID": "01_getting_started.html#vectors",
    "href": "01_getting_started.html#vectors",
    "title": "2  Introduction",
    "section": "2.6 Vectors",
    "text": "2.6 Vectors\nIn R, most of the things we manipulate are vectors, which are sequences of different values on which we can perform operations. These vectors can be of different types (eg : vectors of numbers, vectors of strings) but have to be of the same type (atomic vectors). You would also store elements of different values in lists. Vectors have a type (typof) and a length.\nWe can generate vectors with c().\n\nHow things work in R : vectors, strings and so on\nWhat is an object, what is the environment\n\nNotice that I have write this with an underscore : no space.\nvectors : sequences of things, we can create them with c(), list of values, there are unidimensionals, have only one type\nWe store data as objects and we assign them values on which we can perform operations later on. Objects can be one number, several strings or dataframes as we will see later.\n\nfirst_object <- 2\n\nfirst_object + 4\n\n[1] 6\n\n\nObjects with assignment operator <-, we give a value to an object. Also boolean. There are conventions on how you should write objects names : you can visit this here : https://style.tidyverse.org/syntax.html#object-names\n\n3 > 5\n\n[1] FALSE\n\n\n\n2.6.1 Characters vectors\n\nthis_is_a_vector <- c(\"a\", \"vector\")\n\nstrings and numerics\nGoal to have vectors is to do operations on them."
  },
  {
    "objectID": "01_getting_started.html#base-r-and-the-tidyverse",
    "href": "01_getting_started.html#base-r-and-the-tidyverse",
    "title": "2  Introduction",
    "section": "2.8 Base R and the tidyverse",
    "text": "2.8 Base R and the tidyverse\n\nThe tidyverse is easier, but I will often try to show use how to things in base R because it always could be useful.\nUse the Pipe |> to chain command, thing about a recipe : you follow instructions. When you install it, you will have weird messages but you can ignore them.\n\n\n2.8.1 Dataframes and tibbles\nWe usually do not work directly with vectors but with dataframes. dataframes are combinations of vectors\ntibbles gives you more concise information when you print it, linked with tidyverse functions, “improved” dataframes. Tibbles only can contain vectors of the same type and the same lgenth\n\n# This is a dataframe\nnames <- randomNames::randomNames(5, which.names=\"first\")\n\ngender <- gender::gender(names)\ngender\n\n# A tibble: 3 × 6\n  name    proportion_male proportion_female gender year_min year_max\n  <chr>             <dbl>             <dbl> <chr>     <dbl>    <dbl>\n1 Anna             0.0029             0.997 female     1932     2012\n2 Norma            0.0051             0.995 female     1932     2012\n3 Quinten          1                  0     male       1932     2012\n\nnames\n\n[1] \"Anna\"    \"Quinten\" \"Norma\"   \"Bandar\"  \"Najeeba\"\n\n\n\nmy_data <- tibble::tibble(\n  name = names, # Names\n  master = c(\"Political Behaviour\", \"Public Policy\", \"General Track\", \"IR\", \"Comparative Politics\"), # Track\n  gender = c(\"M\", \"F\", \"M\", \"F\", \"M\"), # Gender\n  mean = c(10.5, 4, 13, 15, 7) # Mean\n)\n\nmy_data\n\n# A tibble: 5 × 4\n  name    master               gender  mean\n  <chr>   <chr>                <chr>  <dbl>\n1 Anna    Political Behaviour  M       10.5\n2 Quinten Public Policy        F        4  \n3 Norma   General Track        M       13  \n4 Bandar  IR                   F       15  \n5 Najeeba Comparative Politics M        7  \n\n\nYou see now that we have a new object in our Environment Pane with 3 observations and 4 variables.\nTo access one variable of a dataframe, we use the $ sign.\nalso List : can have different type of things but we wont go further on this at the moment.\nIndexation : you can access some of the data like this :\n\nmy_data$name[1]\n\n[1] \"Anna\"\n\n\n\nmy_data$name\n\n[1] \"Anna\"    \"Quinten\" \"Norma\"   \"Bandar\"  \"Najeeba\"\n\n\n\nmy_data$name[[1]]\n\n[1] \"Anna\"\n\n\n\nmy_data[[1]]\n\n[1] \"Anna\"    \"Quinten\" \"Norma\"   \"Bandar\"  \"Najeeba\"\n\n\n\nhead(my_data)\n\n# A tibble: 5 × 4\n  name    master               gender  mean\n  <chr>   <chr>                <chr>  <dbl>\n1 Anna    Political Behaviour  M       10.5\n2 Quinten Public Policy        F        4  \n3 Norma   General Track        M       13  \n4 Bandar  IR                   F       15  \n5 Najeeba Comparative Politics M        7  \n\ntail(my_data)\n\n# A tibble: 5 × 4\n  name    master               gender  mean\n  <chr>   <chr>                <chr>  <dbl>\n1 Anna    Political Behaviour  M       10.5\n2 Quinten Public Policy        F        4  \n3 Norma   General Track        M       13  \n4 Bandar  IR                   F       15  \n5 Najeeba Comparative Politics M        7  \n\ndplyr::glimpse(my_data)\n\nRows: 5\nColumns: 4\n$ name   <chr> \"Anna\", \"Quinten\", \"Norma\", \"Bandar\", \"Najeeba\"\n$ master <chr> \"Political Behaviour\", \"Public Policy\", \"General Track\", \"IR\", …\n$ gender <chr> \"M\", \"F\", \"M\", \"F\", \"M\"\n$ mean   <dbl> 10.5, 4.0, 13.0, 15.0, 7.0\n\ncolnames(my_data)\n\n[1] \"name\"   \"master\" \"gender\" \"mean\"  \n\ndim(my_data)\n\n[1] 5 4\n\nnrow(my_data)\n\n[1] 5\n\nsummary(my_data)\n\n     name              master             gender               mean     \n Length:5           Length:5           Length:5           Min.   : 4.0  \n Class :character   Class :character   Class :character   1st Qu.: 7.0  \n Mode  :character   Mode  :character   Mode  :character   Median :10.5  \n                                                          Mean   : 9.9  \n                                                          3rd Qu.:13.0  \n                                                          Max.   :15.0  \n\n\nNo correct way to do stuffs in R, you can do the same things in very different ways : learning how to learn. You cannot remember anything. We do google search all the time. But you need some patience.\nInstall Packages\nthat you need to load with library."
  },
  {
    "objectID": "01_getting_started.html#importing-data",
    "href": "01_getting_started.html#importing-data",
    "title": "2  Introduction",
    "section": "2.9 Importing data",
    "text": "2.9 Importing data\n\n2.9.1 Get data\nLast time we tried to get a sense of what R can do with basic arithmetics but usually we are interested in working with real data. Our goal with R is to use programming to produce analysis of quantitative data. Then the first thing you need is to get that data somewhere, either collect if through a survey, or build a dataset yourself by coding some informations about the individuals or organizations you are interested in. But there are also many many many datasets already available around there that people (administrations, researchers, ngos, companies, international organization and so on) have already created and made available. At this stage, I will give you already-made datasets on which you can work, but you should know that with R, you can collect data directly from the internet : this is called web scraping (you can learn that later on if you continue to)\nSo far, I showed you basic use of R with fake data. But our goal with R is to use programming to produce analysis of quantitative real data to answer social sciences research questions. Then, the first thing you need is to get data. There are a lot of data around us such as :\n\nSurveys : ex : measuring people attitudes\nText\nImage\nCountry characteristics, institutions\nDatasets that other researches have produced\nDatasets that administration, parliaments etc\n\nYou could also consider producing your own datasets through :\n\nProducing your own survey (but you need money)\nScraping\nHand-coding\n\n\n\n2.9.2 Read data into R\nThe first thing we have to do when working with data in importing data into R. This step is crucial, make looks simple but sometimes is not and because datasets comes in very different format. The most common is .csv (for comma separated values), butin political science, you will find also a lot of stata (.dta) or spss (.sav) files. In base R, you can use the read.csv() function to import csv file.\nTo import data here, we will use the readr package, that is part of the tidyverse.\n\nread_r : read_csv, read_csv2\nImportance of paths\nEncoding issues ?\n\n\n\n2.9.3 Write data\nOnce you have done something, that you want to share it or hand it to me for your assignment, you"
  },
  {
    "objectID": "01_getting_started.html#finding-help-and-dealing-with-errors",
    "href": "01_getting_started.html#finding-help-and-dealing-with-errors",
    "title": "2  Introduction",
    "section": "2.12 Finding help and dealing with errors",
    "text": "2.12 Finding help and dealing with errors\nProgramming might be very frustrating because when you learn a new language, you make many mistakes. But R is very strict on what it will accept. So when you want to do something but that you do not ask properly, you will have errors. And finding and understanding the causes of these errors is, in my experience, the best way to learn R.\nThere are different places where you can ask for help when you need. First, you have to understand that the error you will get, many people have got it before you and some of them have asked online. So the first thing to do is to check whether people have already asked the same kind of questions.\nFirst, every function has a documentation written by the person who created it. You can access this documentation directly from Rstudio by adding a question mark in front of the function name and running this line of code. This will give you a description of the function and its use, the different arguments the function can take and examples of its use.\n\n?read_csv\n\nNo documentation for 'read_csv' in specified packages and libraries:\nyou could try '??read_csv'\n\n\nThen you can also just google the error messages you’ve received. Most of the time you’ll come across a blog called Stackoverflow , which brings together a community of users of different programming languages. If R gives you an error and you don’t understand what it means, it’s highly likely that someone has already asked the question, and you can find on the site people who have provided solutions.\nFinally, when you’re writing code, ChatGpt can quickly become one of your best friends. By giving it your error or asking it for instructions to perform certain code tasks, it can perform very well. I encourage you to use it when writing code. Beware, however, that ChatGPT can totally hallucinate and give you functions that don’t exist. It’s not a miracle solution. However, you’ll find out pretty quickly if what it’s given you is true, because if it isn’t, the code won’t work in R."
  },
  {
    "objectID": "01_getting_started.html#exercise-1",
    "href": "01_getting_started.html#exercise-1",
    "title": "2  Introduction",
    "section": "2.13 Exercise 1",
    "text": "2.13 Exercise 1\n\nCreate an R project on your computer in the location and with the name you want (avoid white spaces). This should create a new folder containing an Rproj file.\nCreate a quarto document with the title “Exercise 1” and your name as author. Save the file as (“lastname_ex1.qmd”) and save it in the same folder.\nAdd a chunk code and print out your working directory to make sure your R session is launched in the project you’ve created. The last part of the path displayed should correspond to the project name.\nAdd a new chunk code and find a way to import the Quality of Government environmental indicators dataset into Rstudio, either in .dta format (stata) or .sav format (spss).\nOnce the data has been imported, answer the following questions with both code and writing on the quarto document:\n\n\nWhat is this dataset about ?\nWhat is the unit of analysis for this dataset ?\nFind a way to calculate the mean of the variable wdi_fossil and write a sentence to interpret the result.\n\n\nRender the quarto document in a pdf format and upload your file on moodle. To compile in pdf, you might need to install the tinytext package and it might actually do not work. If it does not just compile into html and send it like this."
  },
  {
    "objectID": "01_getting_started.html#solution-to-exercise-1",
    "href": "01_getting_started.html#solution-to-exercise-1",
    "title": "2  Introduction",
    "section": "2.14 Solution to exercise 1",
    "text": "2.14 Solution to exercise 1\n\nPrint your working directory\n\nFirst, you had to print your working directory. To do this in quarto, you have to add a new cunk code, which you can do by option + command + i in MAC or … in Windocs. You can also click on code and ‘Insert Chunk’ in the functions bar.\n\ngetwd() \n\n[1] \"/Users/malo/Documents/teaching/2023_intro_r\"\n\nhere::here() \n\n[1] \"/Users/malo/Documents/teaching/2023_intro_r\"\n\n\nThe haven package allows you to read both files from Stata or from SPSS with either read_dta() or read_sav(). Here I’ve copied the address of the pdf link on the site and read the file directly from the Internet. I could also have downloaded the file and saved it in the same folder as my project to import it, specifying the file name as the first argument to the read_dta function.\n\nqog <- haven::read_dta(\"https://www.qogdata.pol.gu.se/data/qog_ei_sept21.dta\")\n\n\nqog |> head(10) # Look at the first 10 rows\n\n# A tibble: 10 × 414\n   cname       ccode  year cname_qog   ccode_qog ccodealp ccodealp_year ccodecow\n   <chr>       <dbl> <dbl> <chr>           <dbl> <chr>    <chr>            <dbl>\n 1 Afghanistan     4  1946 Afghanistan         4 AFG      AFG46              700\n 2 Afghanistan     4  1947 Afghanistan         4 AFG      AFG47              700\n 3 Afghanistan     4  1948 Afghanistan         4 AFG      AFG48              700\n 4 Afghanistan     4  1949 Afghanistan         4 AFG      AFG49              700\n 5 Afghanistan     4  1950 Afghanistan         4 AFG      AFG50              700\n 6 Afghanistan     4  1951 Afghanistan         4 AFG      AFG51              700\n 7 Afghanistan     4  1952 Afghanistan         4 AFG      AFG52              700\n 8 Afghanistan     4  1953 Afghanistan         4 AFG      AFG53              700\n 9 Afghanistan     4  1954 Afghanistan         4 AFG      AFG54              700\n10 Afghanistan     4  1955 Afghanistan         4 AFG      AFG55              700\n# ℹ 406 more variables: ccodevdem <dbl>, cname_year <chr>, version <chr>,\n#   act_act <dbl>, as_rifr <dbl>, as_ws <dbl>, bti_envc <dbl>, ccci_coop <dbl>,\n#   ccci_em <dbl>, ccci_fin <dbl>, ccci_kyoto <dbl>, ccci_rep <dbl>,\n#   ccci_unfccc <dbl>, cckp_rain <dbl>, cckp_temp <dbl>, ccl_exepp <dbl>,\n#   ccl_leglp <dbl>, ccl_lpp <dbl>, ccl_mitlpp <dbl>, ccl_nexep <dbl>,\n#   ccl_nlegl <dbl>, ccl_nlp <dbl>, ccl_nmitlp <dbl>, edgar_bc <dbl>,\n#   edgar_ch4 <dbl>, edgar_co <dbl>, edgar_co2gdp <dbl>, edgar_co2pc <dbl>, …\n\nqog |> tail(5) # Look at the last 5 rows\n\n# A tibble: 5 × 414\n  cname         ccode  year cname_qog  ccode_qog ccodealp ccodealp_year ccodecow\n  <chr>         <dbl> <dbl> <chr>          <dbl> <chr>    <chr>            <dbl>\n1 South Vietnam    NA  1972 Vietnam, …       999 VDR      VDR72               NA\n2 South Vietnam    NA  1973 Vietnam, …       999 VDR      VDR73               NA\n3 South Vietnam    NA  1974 Vietnam, …       999 VDR      VDR74               NA\n4 South Vietnam    NA  1975 Vietnam, …       999 VDR      VDR75               NA\n5 South Vietnam    NA  1976 Vietnam, …       999 VDR      VDR76               NA\n# ℹ 406 more variables: ccodevdem <dbl>, cname_year <chr>, version <chr>,\n#   act_act <dbl>, as_rifr <dbl>, as_ws <dbl>, bti_envc <dbl>, ccci_coop <dbl>,\n#   ccci_em <dbl>, ccci_fin <dbl>, ccci_kyoto <dbl>, ccci_rep <dbl>,\n#   ccci_unfccc <dbl>, cckp_rain <dbl>, cckp_temp <dbl>, ccl_exepp <dbl>,\n#   ccl_leglp <dbl>, ccl_lpp <dbl>, ccl_mitlpp <dbl>, ccl_nexep <dbl>,\n#   ccl_nlegl <dbl>, ccl_nlp <dbl>, ccl_nmitlp <dbl>, edgar_bc <dbl>,\n#   edgar_ch4 <dbl>, edgar_co <dbl>, edgar_co2gdp <dbl>, edgar_co2pc <dbl>, …\n\ndplyr::glimpse(qog)\n\nRows: 11,722\nColumns: 414\n$ cname               <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afgh…\n$ ccode               <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ year                <dbl> 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 19…\n$ cname_qog           <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afgh…\n$ ccode_qog           <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ ccodealp            <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"…\n$ ccodealp_year       <chr> \"AFG46\", \"AFG47\", \"AFG48\", \"AFG49\", \"AFG50\", \"AFG5…\n$ ccodecow            <dbl> 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, …\n$ ccodevdem           <dbl> 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36…\n$ cname_year          <chr> \"Afghanistan 1946\", \"Afghanistan 1947\", \"Afghanist…\n$ version             <chr> \"ei_sep21\", \"ei_sep21\", \"ei_sep21\", \"ei_sep21\", \"e…\n$ act_act             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ as_rifr             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ as_ws               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ bti_envc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_coop           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_em             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_fin            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_kyoto          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_rep            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccci_unfccc         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ cckp_rain           <dbl> 20.33333, 21.54167, 23.90000, 23.30833, 23.29167, …\n$ cckp_temp           <dbl> 13.15833, 13.65833, 12.92500, 12.04167, 11.58333, …\n$ ccl_exepp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_leglp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_lpp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_mitlpp          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_nexep           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_nlegl           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_nlp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ccl_nmitlp          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_bc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_ch4           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_co            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_co2gdp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_co2pc         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_co2t          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_n2o           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_nh3           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_nmvoc         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_nox           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_oc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_pm10          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_pm25          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edgar_so2           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_edi             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gaarr           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gadrei          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gaerr           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gair            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gapc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gbs             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gee             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gepd            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gepp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gewi            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gftir           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_ggr             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gicm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gip             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gipirm          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gira            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gpajad          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gper            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gppa            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gppc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gppr            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_grpcspa         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_gser            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_jp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_pati            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ edi_pp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_bcpc             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_bct              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_bul              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_bul_bc           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_bulp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_carb             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_carb_bc          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_carbp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_crop             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_crop_bc          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_cropp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_ef               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_efp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_eft              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_eftp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_fg               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_fg_bc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_fgp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_for              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_for_bc           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_forp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_gl               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_gl_bc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ef_glp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ em_envmin           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ emdat_damage        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 25000, NA, …\n$ emdat_naffect       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, NA, NA, …\n$ emdat_ndeath        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 2000, NA, 151, NA,…\n$ emdat_ndis          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 2, NA, NA, …\n$ emdat_nhome         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, NA, NA, …\n$ emdat_ninj          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 2000, NA, N…\n$ emdat_ntotaff       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 2000, NA, N…\n$ engo_nengo          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_bath            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_car             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_co2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_dete            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_enef            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_ener            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_fors            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_lead            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_nois            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_pawa            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_soil            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epc_watp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_audi_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_audi_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_bath_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_bath_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_car_co         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_car_hc         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_car_nox        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_care_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_care_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cd_dwsum       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cd_upsum       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_ch_kum         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_ch2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cont_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cont_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cowa_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_cowa_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_dete_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_dete_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_ecol_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_ecol_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_eias_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_eias_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_enef_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_enef_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_glas_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_glas_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_glas2_s        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_intro_kum      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_land_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lanr_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lcp_dust       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lcp_nox        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lcp_so2        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lcpt_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lcpt_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lead_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lead_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_lead_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_moto_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_moto_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_moto_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_nois_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_nois_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_nois_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_pact_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_pact_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_pape_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_pape_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_pape2_s        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_soil_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_soil_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_sulp_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_sulp_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_sulp_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_susp_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_susp_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wabo_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_waco_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wacr_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_waef_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_waef_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wale_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wapr_ch2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wapr_in2       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epcc_wazi_s         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_agr             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_air             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_ape             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_bca             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_bdh             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_bhv             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_cch             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_cda             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_cha             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_ecs             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_eh              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_epi             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_ev              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_fct             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_fga             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_fsh             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_fss             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_ghp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_gib             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_grl             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_h2o             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_had             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_hmt             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_lcb             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_mpa             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_msw             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_mti             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_noa             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_nxa             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_ozd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_par             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_pbd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_pmd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_sda             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_shi             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_snm             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_spi             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_tbg             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_tbn             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_tcl             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_usd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_uwd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_wmg             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_wrs             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_wtl             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ epi_wwt             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_banhhap_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_ccnthum_p       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_ccrdprs_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_clmchng_p       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_clmthgt_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_gvsrdcc_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_impenv_m        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_inctxff_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_lklmten_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_sbsrnen_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ess_wrclmch_m       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagr           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrara        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrcrop       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrirrac      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrirreq      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrirreqcrop  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrorg        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrpas        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luagrpcrop      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_lucrop          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luforest        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luforplant      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_luforreg        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ fao_lupas           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_asew_pop         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_asewp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_asews            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_asewt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_buapc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_buapt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_ei               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_envrd_gbaord     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_envrd_gdp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_eoda             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_erdgdp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_etp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_etpw             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_ffrd             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_frs              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_fsmc             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_iufr             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mao              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_ml               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mpm              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mr               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mwgpc            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mwipt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mwlpt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_mwrpt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_oda_ccm          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_pm25ex10p        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_pm25ex35p        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_pm25exm          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_pt               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_re_tpes          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_reperegen        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_rerd_erd         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_tbs              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_tms              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_tps              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_wsa              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ gg_wsi              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ iead_eif1           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_eif2           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_eif3           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_inforce        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_inforce_noterm <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_rat            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_sig            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3,…\n$ iead_term           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_withdraw1      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ iead_withdraw2      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0,…\n$ issp_10am           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_12ap           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_12bp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_12cp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_13am           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_13bm           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_13em           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_13gm           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_15ap           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_18p            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_19am           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_19bm           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_1ap            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_20am           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_20ap           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_20dm           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_21p            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_22ap           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_22bp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_22cp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_6m             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_8am            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_8bm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ issp_9am            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ nrmi_nrpi           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_cctr_gdp       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_cctr_tot       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_eampg          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_epea           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_eps            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_etr_gdp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_etr_tot        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_pm25ex15p      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_pm25ex25p      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ oecd_polagdpg       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_aoacc           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_caacid          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_chp             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_csslr           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_csst            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_cuv             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_fah             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_fchb            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_fclb            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_hab             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_habcom          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_habeez          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_hdinter         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_hshb            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_hssb            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_lpai            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_lpao            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_maricul         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_npblast         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_npcyan          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_ohi             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_pc3             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_pchem           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_pn3             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_pnutrient       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_ptrash          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_saali           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_tjpt            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_tour            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_trsust          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ohi_water           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_exp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_netexp     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_netexpc    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_price      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 12384826, 13319531, 128…\n$ ross_gas_prod       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_value_2000 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_gas_value_2014 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_exp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_netexp     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_netexpc    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_price      <dbl> 9.768706, 14.475370, 14.067980, 12.707120, 12.0830…\n$ ross_oil_prod       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_value_2000 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ross_oil_value_2014 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ sgi_en              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ sgi_enen            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ sgi_enge            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ sgi_epe             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ sgi_ger             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_ex_l3     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_ex_lt     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_l3        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_leg_l3    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_leg_lt    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ slaws_mit_lt        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ vparty_envseat      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ vparty_envvote      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_agrland         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_araland         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_area            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_areabelow       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_co2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_forest          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_fossil          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_idpdis          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_piesr           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_precip          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wdi_tpa             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_ameop           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_ceom            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_deop            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_epmip           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_epmpp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_imeop           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_pedp            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wvs_ploem           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nOr we can have a look at the codebook which we can download with the data that gives us a description of every variable in the dataset.\n\nsummary(qog$wdi_fossil)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   42.22   75.04   65.53   92.13  100.00    6093 \n\nmean(qog$wdi_fossil)\n\n[1] NA\n\nmean(qog$wdi_fossil, na.rm = TRUE)\n\n[1] 65.53438\n\n\n\n2.14.1 Additional ressources"
  },
  {
    "objectID": "00_getting.html#install-r",
    "href": "00_getting.html#install-r",
    "title": "2  Setting up R and Rstudio",
    "section": "2.1 Install R",
    "text": "2.1 Install R\nYou can install R from CRAN (The comprehensive R Archive Network). On the site, you’ll find links to download the version of R you need for your operating system (Windows, Mac or Linux). Then click to download the latest version (it should be 4.3.1) . Once the download is complete, you need to execute the installer.\n Is if has work, perfect. You should know that you can work with this but almost nobody use only R to perform analysis."
  },
  {
    "objectID": "00_getting.html#install-rstudio",
    "href": "00_getting.html#install-rstudio",
    "title": "2  Setting up R and Rstudio",
    "section": "2.2 Install Rstudio",
    "text": "2.2 Install Rstudio\nOnce R is set up, you can install Rstudio. Rstudio is an IDE, you can interact with and have a lot a functionalities.\nhttps://posit.co/download/rstudio-desktop/\nOnce this is done, you can install Rstudio.\nYou might find more information in this tutorial : https://rstudio-education.github.io/hopr/starting.html"
  },
  {
    "objectID": "03_dataviz.html",
    "href": "03_dataviz.html",
    "title": "4  Data vizualisation",
    "section": "",
    "text": "5 Bivariate plots\nNow you should be able to do the following things :\nAussi montrer des geom bar, des geom line dans le temps, des geom col, des geom histogram"
  },
  {
    "objectID": "03_dataviz.html#e",
    "href": "03_dataviz.html#e",
    "title": "4  Data vizualisation",
    "section": "4.1 E",
    "text": "4.1 E\nTo show you the kind of vizualisation, I will use the Chapell Hill Expert Survey (Jan Rovny is one of the Principal Investigator). I you are interested in political parties, it is definitely a dataset you should know. Basically, every 4 years, hundreds of experts in different countries are asked to locate political parties on different scales. For instance : locating a party on a left right scale from 1 to 10. The goal is to map political parties on different dimensions and to be have an idea of the preferences of the party.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nches <- haven::read_dta(\"https://www.chesdata.eu/s/1999-2019_CHES_dataset_meansv3.dta\")  |> \n  mutate(family = as.factor(family)) |> \n  filter(family %in% c(1:7)) |> \n  mutate(family = case_match(\n    family, \n    \"1\" ~ \"Droite Radicale\",\n    \"2\" ~ \"Conservateurs\",\n    \"3\" ~ \"Libéraux\",\n    \"4\" ~ \"Chrétiens-Democrates\",\n    \"5\" ~ \"Socialistes\",\n    \"6\" ~ \"Gauche Radicale\",\n    \"7\" ~ \"Verts\",\n  ), \n  country = labelled::unlabelled(country))\n\nUnivariate plots will be for one variale and bivariate plot to vizualise the relationship between different variables and the plot will depend on the type of your variables. ``"
  },
  {
    "objectID": "03_dataviz.html#to-go-further-with-data-vizualisation",
    "href": "03_dataviz.html#to-go-further-with-data-vizualisation",
    "title": "4  Data vizualisation",
    "section": "8.1 To go further with data vizualisation",
    "text": "8.1 To go further with data vizualisation\n\nHealy datavizualisation\nChapter in R for data science about Data vizualisation (https://r4ds.hadley.nz/visualize.html)\nChapter Irizarry about data vizualisation (http://rafalab.dfci.harvard.edu/dsbook/introduction-to-data-visualization.html)\n\n\n8.1.1 Exercice 3 : vizualising political parties\n\nDownload and import the Chapell Hill Expert Survey trend file into Rstudio\nExplore the codebook to see the variables available in this dataset and choose one of your interest1.\nUsing graphs, provide a brief analysis of how political parties differ on this issue. You should find a way to use at least the following geoms : geom_bar(), geom_point(), geom_boxplot(). If you want to polish the aesthetics of your graphics, take a look at these resources.\nCombine both your code and your analysis in a quarto document, render it in pdf and upload it on moodle.\n\nhttp://vita.had.co.nz/papers/layered-grammar.pdf"
  },
  {
    "objectID": "00_getting.html#set-preferences",
    "href": "00_getting.html#set-preferences",
    "title": "2  Setting up R and Rstudio",
    "section": "2.3 Set preferences",
    "text": "2.3 Set preferences\nRstudio has a whole series of default settings that are worth changing to adopt best practices. Please do the following:\n\nTools > Global Options > RGeneral : here save workspace to never.\nDepending on your taste, you can also change the appearance of Rstudio but that depends on you"
  },
  {
    "objectID": "ressources.html#if-you-want-to-know-more-abour-programming-in-r",
    "href": "ressources.html#if-you-want-to-know-more-abour-programming-in-r",
    "title": "6  Ressources",
    "section": "6.1 If you want to know more abour programming in R",
    "text": "6.1 If you want to know more abour programming in R\n\nR for Data Science\nTelling stories with data\nOther introductions to R :\nhttp://cssbook.net/content/chapter01.html https://rstats.wtf/\n\n-   https://bookdown.org/f_lennert/introduction-to-r/\nOn reproducibility :\n\nhttps://raps-with-r.dev/\n\nFor french speakers :\n\nhttps://juba.github.io/tidyverse/ : Julien barnier\nhttps://larmarange.github.io/guide-R/ : Joseph Larmarange\n\nOn Tidy datasets : https://www.jstatsoft.org/article/view/v059i10 ## Datasets\nFind also fun datasets to use in different regions :\n\nPublic policy : QOG\nInternational Relations\nPolitical Behavior\n\nArab Barometer ? Latinobarometer ?\nEuropean Election Study\nCHES\nKostelka : https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/MYSRXT\nGreta Thunberg speeches\nEss data on energy, fossil fuels support or I dont know what, anthropic\nRessources in French : guide R, laramrange R and Introduction to R Julien Barnier;\n\nWhen you find a dataset online, it is usually accompanied with a codebook containning the informations of the dataset.\n\nDataset exceptius on international organization and human rights : https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/TTS0MF\nQOG dataset\nClimate policy : https://academic.oup.com/isq/article/61/2/253/3949623\nhttps://unfccc.int/process/parties-non-party-stakeholders/non-party-stakeholders/admitted-ngos/list-of-admitted-ngos : may possible to scrap that website"
  },
  {
    "objectID": "02_manipulate.html",
    "href": "02_manipulate.html",
    "title": "3  Manipulating data",
    "section": "",
    "text": "4 Mutate\nOnce we have imported our data, we usually have descriptive sumamry of what it looks like. There are many ways to do that.\nIf you want a summary of all variables, you can test what the skimr function can do. You wan transform it as tibble to have a dataset with different things."
  },
  {
    "objectID": "02_manipulate.html#introduction-to-dplyr-functions",
    "href": "02_manipulate.html#introduction-to-dplyr-functions",
    "title": "3  Manipulating data",
    "section": "3.1 Introduction to dplyr functions",
    "text": "3.1 Introduction to dplyr functions\nTo manipulate data, we will utilize a package from the tidyverse called dplyr, comprising a comprehensive suite of exceptionally useful functions. To familiarize ourselves with its usage, we will explore the Quality of Government Environmental Indicators dataset. To do this, we will need first to load the tidyverse and find the data online. To ensure reproducibility, you can directly download the file in your laptop from R with the download.file() function which two arguments : the url of the dataset and the path you want to save it. Then, we import the data.dta format using the haven package.\n\n# Load the tidyverse\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n# Download the QOG dataset directly from R\n\ndownload.file(\"https://www.qogdata.pol.gu.se/data/qog_ei_ts_sept21.dta\", destfile = \"data/qog_env.dta\")\n\n# Import the qog environment dataset\n\nqog <- haven::read_dta(\"data/qog_env.dta\") \n\n\n3.1.1 count()\nFrom Exercise 1, we saw that the qog dataset has a country-year structure. For each country, we have a series of indicators with one value per year. the qog dataset has a year variable and a country variable.\n\nqog |> \n  count(year)\n\n# A tibble: 75 × 2\n    year     n\n   <dbl> <int>\n 1  1946    75\n 2  1947    76\n 3  1948    82\n 4  1949    85\n 5  1950    88\n 6  1951    88\n 7  1952    89\n 8  1953    89\n 9  1954    91\n10  1955    94\n# ℹ 65 more rows\n\nqog |> \n  count(year, cname)\n\n# A tibble: 11,722 × 3\n    year cname                                n\n   <dbl> <chr>                            <int>\n 1  1946 Afghanistan                          1\n 2  1946 Albania                              1\n 3  1946 Andorra                              1\n 4  1946 Antigua and Barbuda                  1\n 5  1946 Argentina                            1\n 6  1946 Australia                            1\n 7  1946 Belgium                              1\n 8  1946 Bhutan                               1\n 9  1946 Bolivia (Plurinational State of)     1\n10  1946 Brazil                               1\n# ℹ 11,712 more rows\n\n\n\n\n3.1.2 filter()\nWe may want to use only a subset of countries and get a smaller versions of the dataset. And the tiverse has one for this, which is called filter. We want to select specific rows/observations of the dataset based on a specific conditions. To filter, we will use extensively boolean operators.\n\n\n\nOperator\nDescription\n\n\n\n\n==\nequal\n\n\n!=\nnot equal\n\n\n<\nless than\n\n\n<=\nless than or equal\n\n\n>\ngreater than\n\n\n>=\ngreater than or equal\n\n\n|\nor\n\n\n!\nnot\n\n\n%in%\nin the set\n\n\n\nFor instance, I might be only interested in environmental indicators for France. In that case I could filter the whole dataset with only the observations that has France as country variable.\n\nqog |> \n  filter(cname == \"France\") \n\n# A tibble: 75 × 414\n   cname  ccode  year cname_qog      ccode_qog ccodealp ccodealp_year ccodecow\n   <chr>  <dbl> <dbl> <chr>              <dbl> <chr>    <chr>            <dbl>\n 1 France   250  1963 France (1963-)       250 FRA      FRA63              220\n 2 France   250  1964 France (1963-)       250 FRA      FRA64              220\n 3 France   250  1965 France (1963-)       250 FRA      FRA65              220\n 4 France   250  1966 France (1963-)       250 FRA      FRA66              220\n 5 France   250  1967 France (1963-)       250 FRA      FRA67              220\n 6 France   250  1968 France (1963-)       250 FRA      FRA68              220\n 7 France   250  1969 France (1963-)       250 FRA      FRA69              220\n 8 France   250  1970 France (1963-)       250 FRA      FRA70              220\n 9 France   250  1971 France (1963-)       250 FRA      FRA71              220\n10 France   250  1972 France (1963-)       250 FRA      FRA72              220\n# ℹ 65 more rows\n# ℹ 406 more variables: ccodevdem <dbl>, cname_year <chr>, version <chr>,\n#   act_act <dbl>, as_rifr <dbl>, as_ws <dbl>, bti_envc <dbl>, ccci_coop <dbl>,\n#   ccci_em <dbl>, ccci_fin <dbl>, ccci_kyoto <dbl>, ccci_rep <dbl>,\n#   ccci_unfccc <dbl>, cckp_rain <dbl>, cckp_temp <dbl>, ccl_exepp <dbl>,\n#   ccl_leglp <dbl>, ccl_lpp <dbl>, ccl_mitlpp <dbl>, ccl_nexep <dbl>,\n#   ccl_nlegl <dbl>, ccl_nlp <dbl>, ccl_nmitlp <dbl>, edgar_bc <dbl>, …\n\n\nHere, see that the tidyverse functions are a bit clearer that what you could do directly with R base functions. To do the same, here an example of what we would have done :\n\nqog[qog$cname %in% c(\"France\"), ]\n\n# A tibble: 75 × 414\n   cname  ccode  year cname_qog      ccode_qog ccodealp ccodealp_year ccodecow\n   <chr>  <dbl> <dbl> <chr>              <dbl> <chr>    <chr>            <dbl>\n 1 France   250  1963 France (1963-)       250 FRA      FRA63              220\n 2 France   250  1964 France (1963-)       250 FRA      FRA64              220\n 3 France   250  1965 France (1963-)       250 FRA      FRA65              220\n 4 France   250  1966 France (1963-)       250 FRA      FRA66              220\n 5 France   250  1967 France (1963-)       250 FRA      FRA67              220\n 6 France   250  1968 France (1963-)       250 FRA      FRA68              220\n 7 France   250  1969 France (1963-)       250 FRA      FRA69              220\n 8 France   250  1970 France (1963-)       250 FRA      FRA70              220\n 9 France   250  1971 France (1963-)       250 FRA      FRA71              220\n10 France   250  1972 France (1963-)       250 FRA      FRA72              220\n# ℹ 65 more rows\n# ℹ 406 more variables: ccodevdem <dbl>, cname_year <chr>, version <chr>,\n#   act_act <dbl>, as_rifr <dbl>, as_ws <dbl>, bti_envc <dbl>, ccci_coop <dbl>,\n#   ccci_em <dbl>, ccci_fin <dbl>, ccci_kyoto <dbl>, ccci_rep <dbl>,\n#   ccci_unfccc <dbl>, cckp_rain <dbl>, cckp_temp <dbl>, ccl_exepp <dbl>,\n#   ccl_leglp <dbl>, ccl_lpp <dbl>, ccl_mitlpp <dbl>, ccl_nexep <dbl>,\n#   ccl_nlegl <dbl>, ccl_nlp <dbl>, ccl_nmitlp <dbl>, edgar_bc <dbl>, …\n\n\nYou could also filter by all of the countries that are NOT France\n\nqog |> \n  filter(cname != \"France\") |> \n  count(cname)\n\n# A tibble: 203 × 2\n   cname                   n\n   <chr>               <int>\n 1 Afghanistan            75\n 2 Albania                75\n 3 Algeria                58\n 4 Andorra                75\n 5 Angola                 45\n 6 Antigua and Barbuda    75\n 7 Argentina              75\n 8 Armenia                29\n 9 Australia              75\n10 Austria                66\n# ℹ 193 more rows\n\n\nOr you would try with different countries. In that case, you can use %in%.\n\nqog_subset <- qog |>\n  filter(\n    cname %in% c(\n      \"France\",\n      \"Norway\",\n      \"Spain\",\n      \"Denmark\"))\n\nBut we also want to store the data to manipulate it and so it is easier to create an object\n\nqog_subset <- qog |>\n  filter(\n    cname %in% c(\n      \"France\",\n      \"Norway\",\n      \"Spain\",\n      \"Denmark\",\n      \"Netherlands\",\n      \"Poland\",\n      \"Russia\",\n      \"Saudi Arabia\",\n      \"India\"\n    ),\n    year > 1990\n  )\n\nqog_subset |> view()"
  },
  {
    "objectID": "02_manipulate.html#select-columns",
    "href": "02_manipulate.html#select-columns",
    "title": "3  Manipulating data",
    "section": "3.2 Select columns",
    "text": "3.2 Select columns\nNow we want to select one or two variables we are interested in to do some analysis. The select function from the tidyverse is useful to select specifics variables/columns from our dataframe\n\nqog_co2 <- qog_subset |> \n  select(cname, year,  wdi_co2)\n\nqog_co2\n\n# A tibble: 269 × 3\n   cname    year wdi_co2\n   <chr>   <dbl>   <dbl>\n 1 Denmark  1991   11.7 \n 2 Denmark  1992   10.5 \n 3 Denmark  1993   11.0 \n 4 Denmark  1994   11.7 \n 5 Denmark  1995   10.9 \n 6 Denmark  1996   13.7 \n 7 Denmark  1997   11.6 \n 8 Denmark  1998   11.2 \n 9 Denmark  1999   10.4 \n10 Denmark  2000    9.61\n# ℹ 259 more rows\n\n\nHere if you look at the dataframe, it irs order by country and they year, but we could want to see how it changes by country each year easily by arranging our dataframe.\nHere we see that there are NA, because the dataset do not provide co2 per capita in 1946. We could remove these rows with NA\nSee in our environment pane how it changes"
  },
  {
    "objectID": "02_manipulate.html#group_by-and-summarize",
    "href": "02_manipulate.html#group_by-and-summarize",
    "title": "3  Manipulating data",
    "section": "3.3 Group_by and summarize",
    "text": "3.3 Group_by and summarize\n\nqog_co2 |> \n  group_by(cname) |> \n  summarise(mean_co2 = mean(wdi_co2))\n\n# A tibble: 9 × 2\n  cname        mean_co2\n  <chr>           <dbl>\n1 Denmark            NA\n2 France             NA\n3 India              NA\n4 Netherlands        NA\n5 Norway             NA\n6 Poland             NA\n7 Russia             NA\n8 Saudi Arabia       NA\n9 Spain              NA\n\n\nDoes not work, why ? Because we have some NA and the mean do not understand so you have to change\n\nqog_co2 |> \n  group_by(cname) |> \n  summarise(mean_co2 = mean(wdi_co2, na.rm = T))\n\n# A tibble: 9 × 2\n  cname        mean_co2\n  <chr>           <dbl>\n1 Denmark          9.31\n2 France           5.82\n3 India            1.15\n4 Netherlands     10.9 \n5 Norway           8.94\n6 Poland           8.29\n7 Russia          11.5 \n8 Saudi Arabia    16.0 \n9 Spain            6.46\n\nqog_co2 |> \n  group_by(cname) |> \n  summarise(mean_co2 = mean(wdi_co2, na.rm = T)) |> \n  arrange(desc(mean_co2))\n\n# A tibble: 9 × 2\n  cname        mean_co2\n  <chr>           <dbl>\n1 Saudi Arabia    16.0 \n2 Russia          11.5 \n3 Netherlands     10.9 \n4 Denmark          9.31\n5 Norway           8.94\n6 Poland           8.29\n7 Spain            6.46\n8 France           5.82\n9 India            1.15\n\n\nHere we see that on average, the Saudi Arabia, Russia have the highest on the period.\nWe would also wonder which year the emission have been the highest\n\nqog_co2 |> \n  group_by(year) |> \n  summarise(mean_co2 = mean(wdi_co2, na.rm = T)) |> \n  arrange(desc(mean_co2)) \n\n# A tibble: 30 × 2\n    year mean_co2\n   <dbl>    <dbl>\n 1  2006     9.25\n 2  1993     9.19\n 3  2008     9.13\n 4  1992     9.08\n 5  2004     9.03\n 6  2010     9.01\n 7  2015     8.95\n 8  2005     8.91\n 9  1994     8.90\n10  1996     8.88\n# ℹ 20 more rows"
  },
  {
    "objectID": "02_manipulate.html#exercise",
    "href": "02_manipulate.html#exercise",
    "title": "3  Manipulating data",
    "section": "7.1 Exercise",
    "text": "7.1 Exercise"
  },
  {
    "objectID": "03_dataviz.html#exploring-party-politics-with-graphs",
    "href": "03_dataviz.html#exploring-party-politics-with-graphs",
    "title": "4  Data vizualisation",
    "section": "4.3 Exploring party politics with graphs",
    "text": "4.3 Exploring party politics with graphs\nTo learn about how to make graphs, we will use the Chapell Hill Expert Survey. I you are interested in political parties, it is definitely a dataset you should know. Basically, every 4 years, hundreds of experts in different countries are asked to locate political parties on different scales (eg : locating a party on a left-right scale from 0 to 10). The goal is to have an valid overview of where do parties stand in different issues on different countries. To use the data, I read directly the link of the CHES trend stata file that is available on the CHES’s website.\n\nlibrary(tidyverse) # Load the tidyverse that contains the ggplot package\n\nches <- haven::read_dta(\"https://www.chesdata.eu/s/1999-2019_CHES_dataset_meansv3.dta\")\n\nches |> glimpse()\n\nRows: 1,196\nColumns: 84\n$ country                <dbl+lbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ eastwest               <dbl+lbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ eumember               <dbl+lbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ year                   <dbl> 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999,…\n$ expert                 <dbl> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 1…\n$ party_id               <dbl> 115, 109, 107, 106, 110, 111, 103, 113, 114, 10…\n$ cmp_id                 <dbl> NA, 21521, 21421, 21422, 21913, 21912, 21321, N…\n$ party                  <chr> \"FN\", \"CVP\", \"PVV/VLD\", \"PRL\", \"VU\", \"FDF\", \"SP…\n$ vote                   <dbl> 1.5, 14.1, 14.3, 7.7, 5.6, 2.4, 9.6, NA, NA, 5.…\n$ seat                   <dbl> 0.7, 14.7, 15.3, 9.0, 5.3, 3.0, 9.3, NA, NA, 6.…\n$ electionyear           <dbl> 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999,…\n$ epvote                 <dbl> 1.52, 13.49, 13.61, 6.69, 7.57, 3.34, 8.84, NA,…\n$ family                 <dbl+lbl> 1, 4, 3, 3, 8, 8, 5, 4, 8, 4, 5, 7, 1, 7, 5…\n$ govt                   <dbl+lbl> 0.0, 0.5, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0…\n$ eu_position            <dbl+lbl> 2.142857, 6.888889, 6.666667, 6.555555, 5.0…\n$ eu_salience            <dbl> 1.562500, 4.722222, 4.166667, 4.166667, 3.61111…\n$ eu_dissent             <dbl> 2.0833335, 0.8333334, 0.8333334, 0.8333334, 1.8…\n$ eu_blur                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ eu_benefit             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ eu_ep                  <dbl+lbl> 4.000000, 6.250000, 6.250000, 6.250000, 6.0…\n$ eu_fiscal              <dbl+lbl> 2.800000, 6.000000, 5.625000, 5.625000, 5.2…\n$ eu_intmark             <dbl+lbl>   NA,   NA,   NA,   NA,   NA,   NA,   NA,  …\n$ eu_employ              <dbl+lbl> 2.500000, 5.666667, 4.625000, 4.625000, 5.4…\n$ eu_budgets             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ eu_agri                <dbl+lbl>   NA,   NA,   NA,   NA,   NA,   NA,   NA,  …\n$ eu_cohesion            <dbl+lbl> 1.666667, 5.875000, 5.375000, 5.625000, 5.3…\n$ eu_environ             <dbl+lbl> 3.600000, 5.555555, 5.125000, 5.000000, 5.4…\n$ eu_asylum              <dbl+lbl> 1.250000, 5.555555, 5.500000, 5.500000, 5.0…\n$ eu_foreign             <dbl+lbl> 2.000000, 6.555555, 6.555555, 6.555555, 4.8…\n$ eu_turkey              <dbl+lbl>   NA,   NA,   NA,   NA,   NA,   NA,   NA,  …\n$ lrgen                  <dbl+lbl> 9.888889, 5.777778, 7.111111, 6.666667, 5.1…\n$ lrecon                 <dbl+lbl> 8.750000, 5.750000, 7.625000, 7.000000, 5.0…\n$ lrecon_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lrecon_dissent         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lrecon_blur            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ galtan                 <dbl+lbl> 9.750000, 7.375000, 5.125000, 4.714286, 4.0…\n$ galtan_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ galtan_dissent         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ galtan_blur            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ spendvtax              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ spendvtax_salience     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ deregulation           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dereg_salience         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ redistribution         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ redist_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ econ_interven          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ civlib_laworder        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ civlib_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ sociallifestyle        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ social_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ religious_principles   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ relig_salience         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ immigrate_policy       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ immigrate_salience     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ immigrate_dissent      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ multiculturalism       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ multicult_salience     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ multicult_dissent      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ urban_rural            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ urban_salience         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ environment            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ enviro_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ cosmo                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ cosmo_salience         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ protectionism          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ regions                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ region_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ international_security <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ international_salience <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ us                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ us_salience            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ethnic_minorities      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ethnic_salience        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ nationalism            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ russian_interference   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ anti_islam_rhetoric    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ people_vs_elite        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ antielite_salience     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ corrupt_salience       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ members_vs_leadership  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ mip_one                <dbl+lbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ mip_two                <dbl+lbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ mip_three              <dbl+lbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ chesversion            <dbl> 2020.1, 2020.1, 2020.1, 2020.1, 2020.1, 2020.1,…\n\nn_distinct(ches$country)\n\n[1] 28\n\nn_distinct(ches$year)\n\n[1] 6\n\nn_distinct(ches$party_id)\n\n[1] 424\n\n\nThe dataset covers information on 424 different political parties, on 6 different waves and in 28 different countries. From the list of variables we can see that a few of them gives us variables on the year, the country, the party, its vote share and number of seats for a given wave and then a lot of variables on different issues. Broadly, we can distinguish between positions, salience, blurring and dissent.\nFor instance, I want to know how political parties in Europe care about russian interference in their country. There is a russian_interference in the CHES on this asking the salience of Russian interference in domestic affaires for the party leasdership : going from No importance to Great importance. The first think we would like to know is how this variable is distributed. To do this we could first calculate some descriptive statistics.\n\nsummary(ches$russian_interference)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.9231  2.5556  2.6381  4.0648  9.4545     949 \n\n\nThe first thing we can see is that there are a lot of NAs. If you have not looked at the codebook carefully, you could wonder why. And this is because our dataset is composed with different waves at different years and the questions. One way to check it is to look at the mean by groups for different years. We see that there are no values before 2019.\n\nches |> group_by(year) |> \n  summarise(m = mean(russian_interference, na.rm = T))\n\n# A tibble: 6 × 2\n   year      m\n  <dbl>  <dbl>\n1  1999 NaN   \n2  2002 NaN   \n3  2006 NaN   \n4  2010 NaN   \n5  2014 NaN   \n6  2019   2.64\n\n\nBut we would have a better understanding on how the values are distributed with a vizualization. With this we know that most of the parties do not think it is important, the mean is quite low and there only a few parties above the mean. But the most important know is to understand how does this vary across different groups such as countries, families to understand why some partis more than other think russian interference is a problem.\nLet’s first have a look on how the data is distributed. For this I create a ggplot with the russian_interference variable and I add a geom_histogram(). This function can take a bin argument where you can specify the number of bins you want in your graph.\n\nches |> \n  ggplot(aes(russian_interference)) + \n  geom_histogram(bins = 30)\n\n\n\n\nWe might assume that however, there is some variance across countries. Looking at the codebook, we see that there is an eastwest variable in the dataset distinguishing western and eastern european countries. The data is coded as 0 or 1 with a label coming from Stata. However, I want to replace these and I use the unlabelled function from the labelled package for this, that allows me to convert the 0 and 1 to their labels.\n\nches |> count(eastwest)\n\n# A tibble: 2 × 2\n  eastwest      n\n  <dbl+lbl> <int>\n1 0 [east]    439\n2 1 [west]    757\n\nches <- ches |> mutate(eastwest = labelled::unlabelled(eastwest))\n\nches |> count(eastwest)\n\n# A tibble: 2 × 2\n  eastwest     n\n  <fct>    <int>\n1 east       439\n2 west       757\n\n\nTo see whether the salience of russian interferance varies across region, we need to plot a bivariate graphs where we can compare the two distributions. A first way to do this is to differentiate the region by color.\n\nches |> \n  ggplot(aes(russian_interference, fill = eastwest)) +\n  geom_histogram(bins = 10)\n\nWarning: Removed 949 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nHowever, as the two colors, overlap, it might be easier to have the two graphs side by side. This can be done by adding a layer with facet_wrap().\n\nches |> \n  ggplot(aes(russian_interference)) +\n  geom_histogram(bins = 10) +\n  facet_wrap(~ eastwest)\n\nWarning: Removed 949 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nHere we can see that our intuition was correct. Comparing the two i\n\nches |> \n  ggplot(aes(eastwest, russian_interference)) +\n  geom_boxplot()\n\nWarning: Removed 949 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\nches |> \n  ggplot(aes(russian_interference, y = after_stat(density))) +\n  geom_freqpoly(aes(color = as.factor(eastwest)))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 949 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nWe can also look at how this varies across countries. As the ches$country variable is coded by countrycodes that are not meaningful, I also convert them with their labels as I did for the region.\n\nches <- ches |> mutate(country = labelled::unlabelled(country))\nches |> count(country)\n\n# A tibble: 28 × 2\n   country     n\n   <fct>   <int>\n 1 be         72\n 2 dk         55\n 3 ge         45\n 4 gr         40\n 5 esp        74\n 6 fr         61\n 7 irl        41\n 8 it         84\n 9 nl         61\n10 uk         42\n# ℹ 18 more rows\n\n\n\nches |>\n  group_by(eastwest, country) |>\n  summarise(mean_russ = mean(russian_interference, na.rm = TRUE)) |>\n  ggplot(aes(fct_reorder(country, mean_russ), mean_russ, fill = as.factor(eastwest))) +\n  geom_col() +\n  coord_flip() +\n  scale_x_discrete(\"Country\") +\n  scale_y_continuous(\"Salience of russian interference\") +\n  scale_fill_brewer(\"Region\", palette = \"Set1\") +\n  theme_minimal()\n\n`summarise()` has grouped output by 'eastwest'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\nches <- ches |> \n  mutate(family = as.factor(family)) |> \n  filter(family %in% c(1:7)) |> \n  mutate(family = case_match(\n    family, \n    \"1\" ~ \"Droite Radicale\",\n    \"2\" ~ \"Conservateurs\",\n    \"3\" ~ \"Libéraux\",\n    \"4\" ~ \"Chrétiens-Democrates\",\n    \"5\" ~ \"Socialistes\",\n    \"6\" ~ \"Gauche Radicale\",\n    \"7\" ~ \"Verts\",\n  ))\n\n\nches |> \n  ggplot(aes(lrgen, russian_interference)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 760 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 760 rows containing missing values (`geom_point()`).\n\n\n\n\nches |> \n  ggplot(aes(lrgen, russian_interference, color = eastwest)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 760 rows containing non-finite values (`stat_smooth()`).\nRemoved 760 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nches |>\n  ggplot(aes(\n    fct_reorder(as.factor(govt), russian_interference),\n    russian_interference, fill = eastwest)) +\n  geom_boxplot() \n\nWarning: `fct_reorder()` removing 760 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n`fct_reorder()` removing 760 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n\n\nWarning: Removed 760 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\nches |>\n  filter(eastwest == \"east\") |> \n  ggplot(aes(\n    fct_reorder(family, russian_interference),\n    russian_interference,\n  fill = as.factor(govt))) +\n  geom_boxplot() \n\nWarning: `fct_reorder()` removing 269 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n\n\nWarning: `fct_reorder()` removing 269 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n\n\nWarning: Removed 269 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\nches$international_security\n\n  [1]       NA       NA       NA       NA       NA       NA       NA       NA\n  [9]       NA       NA       NA       NA       NA       NA       NA       NA\n [17]       NA       NA       NA       NA       NA       NA       NA       NA\n [25]       NA       NA       NA       NA       NA 5.500000 6.454545 7.833333\n [33] 4.181818 3.727273 4.909091 7.000000 6.090909 4.500000 6.545455 3.818182\n [41] 5.000000 4.800000 5.800000 3.400000 5.800000 7.200000 7.800000 3.400000\n [49] 7.200000 4.800000 3.400000 6.000000       NA       NA       NA       NA\n [57]       NA       NA       NA       NA       NA       NA       NA       NA\n [65]       NA       NA       NA       NA       NA       NA       NA       NA\n [73]       NA       NA       NA       NA       NA       NA       NA       NA\n [81]       NA       NA       NA       NA 7.100000 3.750000 5.400000 4.300000\n [89] 4.100000 3.000000 3.000000 3.800000 3.222222 3.777778 7.777778 6.000000\n [97] 1.666667 4.333333 4.000000 2.000000       NA       NA       NA       NA\n[105]       NA       NA       NA       NA       NA       NA       NA       NA\n[113]       NA       NA       NA       NA       NA       NA       NA       NA\n[121]       NA       NA       NA       NA       NA       NA       NA       NA\n[129]       NA       NA 2.800000 5.866667 8.066667 4.066667 3.461539 2.642857\n[137] 7.000000 5.090909 8.800000 7.000000 4.222222 4.636364 4.090909 5.363636\n[145]       NA       NA       NA       NA       NA       NA       NA       NA\n[153]       NA       NA       NA       NA       NA       NA       NA       NA\n[161]       NA       NA       NA       NA       NA       NA       NA       NA\n[169] 5.888889 5.250000 8.363636 8.666667 3.800000 4.000000 9.090909 5.285714\n[177] 4.428571 5.142857 5.000000 9.000000 4.714286 4.375000 4.714286 7.000000\n[185]       NA       NA       NA       NA       NA       NA       NA       NA\n[193]       NA       NA       NA       NA       NA       NA       NA       NA\n[201]       NA       NA       NA 3.363636 3.909091 5.900000 3.833333 2.444444\n[209] 7.000000 4.000000 2.666667 7.500000 7.111111       NA       NA       NA\n[217]       NA       NA       NA       NA       NA       NA       NA       NA\n[225]       NA       NA       NA       NA       NA       NA       NA       NA\n[233]       NA       NA       NA       NA       NA       NA       NA       NA\n[241]       NA       NA       NA       NA       NA       NA       NA       NA\n[249] 7.333333 5.875000 6.400000 7.000000 5.000000 3.375000 5.400000 5.166667\n[257] 5.000000 6.300000 4.400000 3.300000 4.000000 7.142857 3.800000 6.222222\n[265] 5.200000 4.000000 4.250000 4.250000 5.000000 2.777778       NA       NA\n[273]       NA       NA       NA       NA       NA       NA       NA       NA\n[281]       NA       NA       NA       NA       NA       NA       NA       NA\n[289]       NA       NA       NA       NA       NA       NA       NA 3.833333\n[297] 3.833333 5.166667 7.714286 6.833333 8.000000 8.000000 4.200000 4.000000\n[305] 6.200000 4.000000       NA       NA       NA       NA       NA       NA\n[313]       NA       NA       NA       NA       NA       NA       NA       NA\n[321]       NA       NA       NA       NA       NA       NA       NA       NA\n[329]       NA       NA       NA       NA       NA       NA       NA       NA\n[337]       NA       NA       NA       NA       NA       NA       NA       NA\n[345]       NA       NA       NA       NA       NA       NA       NA       NA\n[353] 7.142857 5.000000 3.285714 6.500000 7.666667 7.400000 3.625000 8.250000\n[361] 2.250000 2.571429 4.000000 3.000000 3.500000 3.600000 2.600000 4.600000\n[369] 8.200000 9.000000 2.400000       NA       NA       NA       NA       NA\n[377]       NA       NA       NA       NA       NA       NA       NA       NA\n[385]       NA       NA       NA       NA       NA       NA       NA       NA\n[393]       NA       NA       NA       NA       NA       NA 2.400000 5.000000\n[401] 2.100000 5.300000 4.000000 7.200000 5.600000 7.100000 3.500000 5.125000\n[409] 4.375000 7.500000 7.500000 7.333333 3.625000 3.125000       NA       NA\n[417]       NA       NA       NA       NA       NA       NA       NA       NA\n[425]       NA       NA       NA       NA       NA       NA       NA       NA\n[433]       NA       NA       NA       NA 5.857143 2.923077 3.076923 4.538462\n[441] 4.500000 7.900000 6.800000 5.000000 4.285714 4.571429 3.714286       NA\n[449]       NA       NA       NA       NA       NA       NA       NA       NA\n[457]       NA       NA       NA       NA       NA       NA       NA       NA\n[465]       NA       NA       NA 3.000000 3.166667 7.000000 2.666667 7.000000\n[473] 9.200000 9.200000 6.000000 3.000000 4.000000 3.200000       NA       NA\n[481]       NA       NA       NA       NA       NA       NA       NA       NA\n[489]       NA       NA       NA       NA       NA       NA       NA       NA\n[497]       NA       NA       NA       NA       NA       NA 6.230769 5.153846\n[505] 6.000000 6.000000 4.076923 7.111111 5.400000 5.600000 5.000000 6.000000\n[513] 7.500000       NA       NA       NA       NA       NA       NA       NA\n[521]       NA       NA       NA       NA       NA       NA       NA       NA\n[529]       NA       NA       NA       NA       NA 5.111111 4.555555 5.111111\n[537] 5.888889 5.777778 5.222222 4.571429 6.000000 4.125000 5.000000 5.714286\n[545]       NA       NA       NA       NA       NA       NA       NA       NA\n[553]       NA       NA       NA       NA       NA       NA       NA       NA\n[561]       NA       NA       NA       NA       NA       NA       NA       NA\n[569]       NA 2.500000 7.642857 5.000000 6.785714 3.285714 2.785714 7.125000\n[577] 3.714286 2.210526 6.352941 3.894737 6.368421 7.473684 2.526316 3.263158\n[585]       NA       NA       NA       NA       NA       NA       NA       NA\n[593]       NA       NA       NA       NA       NA       NA       NA       NA\n[601]       NA       NA 8.250000 5.000000 5.750000 6.666667 3.285714 3.857143\n[609] 5.571429 3.875000 3.500000 3.600000 3.642857 9.214286 3.200000 8.461538\n[617] 6.166667 4.833333 8.000000 6.285714       NA       NA       NA       NA\n[625]       NA       NA       NA       NA       NA       NA       NA       NA\n[633]       NA       NA       NA       NA       NA       NA       NA       NA\n[641] 4.062500 2.625000 4.636364 2.000000 8.562500 5.875000 5.400000 6.700000\n[649] 4.818182 5.111111 3.000000 2.250000 2.416667 4.583333 8.416667       NA\n[657]       NA       NA       NA       NA       NA       NA       NA       NA\n[665]       NA       NA 2.083333 1.727273 5.333333 4.500000 3.000000 2.400000\n[673] 1.125000 1.375000 1.000000 1.285714 3.571429       NA       NA       NA\n[681]       NA       NA       NA       NA       NA       NA       NA       NA\n[689]       NA       NA       NA       NA       NA 3.300000 5.200000 4.857143\n[697] 8.142858 6.090909 3.642857 4.214286 3.181818 5.545455 8.545455 3.909091\n[705] 5.181818       NA       NA       NA       NA       NA       NA       NA\n[713]       NA       NA       NA       NA       NA       NA       NA       NA\n[721]       NA       NA       NA       NA       NA       NA       NA       NA\n[729] 3.571429 5.125000 3.500000 6.750000 3.250000 7.625000 2.000000 8.857142\n[737] 3.875000 6.500000 2.250000       NA       NA       NA       NA       NA\n[745]       NA       NA       NA       NA       NA       NA       NA       NA\n[753]       NA       NA       NA       NA       NA       NA       NA       NA\n[761]       NA       NA       NA       NA 4.000000 4.900000 3.083333 5.454545\n[769] 3.600000 3.916667 4.000000 5.000000 7.571429 3.454545 5.200000 4.090909\n[777] 5.444445 3.363636       NA       NA       NA       NA       NA       NA\n[785]       NA       NA       NA       NA       NA       NA       NA       NA\n[793]       NA       NA       NA       NA 2.428571 5.000000 4.428571 4.214286\n[801] 4.272727 8.181818 3.764706 5.111111 5.058824 5.100000 3.588235 6.266667\n[809]       NA       NA       NA       NA       NA       NA       NA       NA\n[817]       NA       NA       NA       NA       NA       NA       NA       NA\n[825]       NA       NA 2.523809 7.600000 4.714286 5.294117 5.000000 2.785714\n[833] 3.133333 4.090909 3.076923 3.200000 3.785714 2.600000       NA       NA\n[841]       NA       NA       NA       NA       NA       NA       NA       NA\n[849]       NA       NA       NA       NA       NA       NA       NA       NA\n[857]       NA 7.500000 4.600000 8.428572 4.307693 5.307693 4.727273 4.272727\n[865] 3.461539 5.230769 4.125000 8.000000 5.000000 4.363636 5.250000 3.285714\n[873] 4.800000       NA       NA       NA       NA       NA       NA       NA\n[881]       NA       NA       NA       NA       NA       NA       NA       NA\n[889]       NA       NA       NA       NA       NA       NA       NA       NA\n[897]       NA 5.000000 5.000000 7.222222 3.818182 5.714286 4.818182 3.818182\n[905] 2.666667 3.000000 6.714286 5.833333 4.833333 3.000000 4.400000       NA\n[913]       NA       NA       NA       NA       NA       NA 3.500000 7.000000\n[921] 4.400000 2.125000 4.400000 6.200000 3.714286 3.375000       NA       NA\n[929]       NA       NA       NA       NA       NA       NA       NA 7.333333\n[937] 4.333333       NA       NA 5.000000 3.000000 1.500000 1.500000 1.500000\n[945] 8.500000       NA       NA       NA       NA       NA       NA 5.000000\n[953] 1.500000 4.000000 2.000000 4.000000 9.500000       NA       NA       NA\n[961]       NA       NA       NA       NA\nattr(,\"label\")\n[1] \"position: international security and peacekeeping missions\"\nattr(,\"format.stata\")\n[1] \"%8.0g\""
  },
  {
    "objectID": "03_dataviz.html#section",
    "href": "03_dataviz.html#section",
    "title": "4  Data vizualisation",
    "section": "8.2 ",
    "text": "8.2 \nTufte : he Visual Display of Quantitative Information - https://www.youtube.com/watch?v=G2lMBNkbggg : Chris Bail on dataviz - https://socviz.co/index.html#preface https://github.com/briatte/dsr/wiki/readings#4-visualization"
  },
  {
    "objectID": "03_dataviz.html#combine-different-graphs",
    "href": "03_dataviz.html#combine-different-graphs",
    "title": "4  Data vizualisation",
    "section": "5.1 Combine different graphs",
    "text": "5.1 Combine different graphs"
  },
  {
    "objectID": "03_dataviz.html#export-graphs",
    "href": "03_dataviz.html#export-graphs",
    "title": "4  Data vizualisation",
    "section": "5.2 Export graphs",
    "text": "5.2 Export graphs\n\n5.2.1 Exercice 3 : vizualising political parties\n\nDownload and import the Chapell Hill Expert Survey trend file into Rstudio\nExplore the codebook to see the variables available in this dataset and choose one of your interest1.\nUsing graphs, provide a brief analysis of how political parties differ on this issue. You should find a way to use at least the following geoms : geom_bar(), geom_point(), geom_boxplot(). If you want to polish the aesthetics of your graphics, take a look at these resources.\nCombine both your code and your analysis in a quarto document, render it in pdf and upload it on moodle."
  },
  {
    "objectID": "03_dataviz.html#to-go-further",
    "href": "03_dataviz.html#to-go-further",
    "title": "4  Data vizualisation",
    "section": "5.3 To go further",
    "text": "5.3 To go further\n\nR Graphics Cookbook\nggplot2:Elegant graphics for data analysis\nKieran Healy’s has written a whole book on dataviz. See also his paper on ARS : Data viz and sociology\nOther book by Claus O Wilke on dataviz\nChapter on dataviz in the R for Data science book\nhttps://clauswilke.com/dataviz/\nChapter by Irizarry in his book\nA paper by Hadley Wickham explaining the idea of “grammar of graphics”\nIf you would also like to learn how to animate your graphs, you can consult the gganimate package.\nTutfte : The visual display of quantitative information\nA video by Chris Bail introducing dataviz\nOther ressources pointed out by François Briatte on github\nGGplot extensions : https://exts.ggplot2.tidyverse.org/gallery/\nhttps://stackoverflow.com/questions/tagged/ggplot2"
  },
  {
    "objectID": "00_getting.html#installing-package",
    "href": "00_getting.html#installing-package",
    "title": "2  Setting up R and Rstudio",
    "section": "2.4 Installing package",
    "text": "2.4 Installing package\nTo make sur everything works, try to install a package by typing “install.package(”tidyverse)” inside the bottom left pane and click enter. It should take a moment. But if at the end no error, you are ready to go. If you have some errors, please write me an email."
  },
  {
    "objectID": "01_getting_started.html#what-is-programming-and-what-you-would-need-that-in-social-sciences",
    "href": "01_getting_started.html#what-is-programming-and-what-you-would-need-that-in-social-sciences",
    "title": "2  Introduction",
    "section": "2.4 What is programming and what you would need that in social sciences",
    "text": "2.4 What is programming and what you would need that in social sciences\nI really want to make a case for why this class is very important.\n\nWhy programming and what is could be useful for :\nData manipulation\nBut also lot of fancier stuff that are more and more used in social sciences (web scraping, social networks analysis, maps, text analysis, image analysis, machine learning)\nIf you are qualitative researcher : free and very powerful automatic transcription algorithms such as whisper but that can be useful when you programm (see whisper)\nThis class is just intro so we will not cover all of these but I can give you more ressources if you want to learn and at the end of this class, you should be definitely able to go in depth by yourself in some of these topics."
  },
  {
    "objectID": "01_getting_started.html#literate-programming",
    "href": "01_getting_started.html#literate-programming",
    "title": "2  Introduction",
    "section": "2.10 Literate programming",
    "text": "2.10 Literate programming\nLiteeate progrmming (Knuth 1984) I already told you about replication and eveyrhing. Rstudio allows you to combine text and code in the same documents. I will try to introduce you to these tools because there are really nice to write.\n\nScript : way to write down code, you do not have to write everything again next time\n\nWhen you open a quarto document, you will have to fill the top matter, called tha YAML\n\nOr literate programming documents : Quarto/Rmarkdown : documents that allows you to combine text and code and then to convert them in pdf, word or html format.\n\nNotions : script, code, programmation\n\nR script : write code and # with comments"
  },
  {
    "objectID": "01_getting_started.html#getting-help-and-dealing-with-errors",
    "href": "01_getting_started.html#getting-help-and-dealing-with-errors",
    "title": "2  Introduction",
    "section": "2.12 Getting help and dealing with errors",
    "text": "2.12 Getting help and dealing with errors\nWhen learning a new language, we inevitably make mistakes. Programming can be highly frustrating because it throws numerous errors at us. Unlike when practicing a new language with foreigners, R is exceptionally strict in what it accepts. If you don’t ask correctly, it won’t comprehend anything. Therefore, you must discover ways to identify and understand the root causes of these errors.\nOvercome the errors is one of the most effective methods to learn R. Here a few places where you wan find the help you will need.\n\n2.12.1 R documentation\nEvery function/package has a documentation written by those who created it. You can access it directly from Rstudio by adding a ? in front of it in the console and run this line of code. This will open a description displayed on the help pane of the function, the different arguments it can take and a few examples of it use. For instance\n\n?read_csv\n\n\n\n2.12.2 Cheatsheets\nEvery package of the tidyverse (and some other) have a cheatsheat with a lot of infos of the different functions available on this link. See for instance the reader cheatsheet.\n\n\n2.12.3 Online ressources\nFirst, you have to understand that the error you will get, many people have got it before you and some of them have asked online. So the first thing to do is to check whether people have already asked the same kind of questions. If R gives you an error and you don’t understand what it means, it’s highly likely that someone has already asked the question, and you can find on the site people who have provided solutions. You will also find help googling what you are looking for. Either when you want to do something (eg : “how to import a .dta file in R’), or when you want to deal with an error, just google the error. Most of the time you’ll come across a blog called Stackoverflow , which brings together a community of users of different programming languages. In general, be aware that in programming, everyone copy and paste the code of everyone. You might also visit the website or Rstudio Commmunity and look at the #rstats on twitter.\n\n\n2.12.4 AI is your friend\nFinally, when you write code, ChatGPT can quickly become one of your closest allies. By providing it with your errors or asking for instructions to accomplish specific coding tasks, it can perform exceptionally well. I highly recommend utilizing it in your coding endeavors. However, be cautious as ChatGPT may occasionally produce non-existent functions or hallucinate. It’s not a miraculous solution. Nevertheless, you’ll swiftly realize whether the information provided is accurate or not because if it isn’t, the code won’t function properly in R.\n\n\n2.12.5 Most common errors\nFinally, some errors are really common and you will probably face them often. I provide you here a (non exhaustive) list of those to help you troubleshooting1.\n\n2.12.5.1 Syntax errors\nMost of “beginners” errors in R are syntax errors : you mis code something and so Rstudio really does not understand. It can be typos when writing function and forgetting about a ), ,, \". For instance, you would forget a closing \" when wanting to subset the Meloni string of in the politicians vector : politicians[politicians == \"Meloni]. In that case you will probably see a + in the console, meaning that R is waiting for something more to compute what you want to do.\n\n\n2.12.5.2 The “not found” errors\n\nError: function 'x' not found : mispelling or package not loaded\n\n\nmeans(c(15,16,19)) \n\nError in means(c(15, 16, 19)): could not find function \"means\"\n\nread_html(\"https://labour.org.uk/category/latest/press-release/\")\n\nError in read_html(\"https://labour.org.uk/category/latest/press-release/\"): could not find function \"read_html\"\n\n\nIn the first case, we want to compute the mean of a vector of different numbers. But we made a typo by adding a s to the mean() function, leading to an error. In the second we try to read the html code of a webpage, which is useful when we want to do web scraping. In that case, the function is correct, but we have not load the rvest package that provide this function before. So when you face this error, check both the spelling of the function and make sure its package is loaded (with library(rvest) for instance).\n\nError: object 'x' not found : typo, forgot to run the line or saving object\n\n\npolitician[1]\n\nError in eval(expr, envir, enclos): object 'politician' not found\n\n\nYou might alo want to look at only the politicians from the EU and the object eu_politicians. Here, the error happens because we did not save any object with this value yet.\n\neu_politicians\n\nError in eval(expr, envir, enclos): object 'eu_politicians' not found\n\neu_politicians <- politicians[!politicians %in% c(\"Biden\", \"Sunak\")]\neu_politicians\n\n[1] \"Macron\"  \"Schultz\" \"Sanchez\" \"Meloni\" \n\n\nError in install.packages : object 'rvest' not found\n\ninstall.packages(rvest)\n\nError in eval(expr, envir, enclos): object 'rvest' not found\n\n\nMost of the time, you just forget the \"\" and you should write install.packages(\"rvest\"). It might also be a typo in the package name (eg. you would have an error with install.packag(\"Rvest\").\n\nError: cannot open the connection non-numeric argument to binary operator"
  },
  {
    "objectID": "functions.html#importing-data",
    "href": "functions.html#importing-data",
    "title": "5  Useful functions",
    "section": "5.1 Importing data",
    "text": "5.1 Importing data\n\nread.csv()\nread.csv2()\nreadr::read_csv()\nreadr::read_csv2()\nreadr::read_delim()\nreadr::read_rds()\nhaven::read_sav()\nhaven::read_dta()\nhaven::read_delim()\nreadxl::read_excel()\nopenxlsx::read.xlsx()"
  },
  {
    "objectID": "functions.html#getting-an-idea-of-the-data",
    "href": "functions.html#getting-an-idea-of-the-data",
    "title": "5  Useful functions",
    "section": "5.2 Getting an idea of the data",
    "text": "5.2 Getting an idea of the data\n\nnrow()\nncol()\nsummary()\ndplyr::glimpse()"
  },
  {
    "objectID": "functions.html#describing-data",
    "href": "functions.html#describing-data",
    "title": "5  Useful functions",
    "section": "5.3 Describing data",
    "text": "5.3 Describing data\n\nsummary()\ntable()\njanitor::tabyl()\nmean()\nmedian()\nsd()"
  },
  {
    "objectID": "functions.html#manipulate-data",
    "href": "functions.html#manipulate-data",
    "title": "5  Useful functions",
    "section": "5.4 Manipulate data",
    "text": "5.4 Manipulate data\n\ndplyr::count()\ndplyr::select()\ndplyr::filter()\ndplyr::arrange()\ndplyr::mutate()\ndplyr::group_by()\ndplyr::summarise()\ndplyr::rename()\ndplyr::rename()\ndplyr::slice_min()\ndplyr::slice_max()"
  },
  {
    "objectID": "functions.html#clean-and-recode",
    "href": "functions.html#clean-and-recode",
    "title": "5  Useful functions",
    "section": "5.5 Clean and recode",
    "text": "5.5 Clean and recode\n\ntidyr::pivot_longer()\ntidyr::pivot_wider()"
  },
  {
    "objectID": "functions.html#testing-bivariate-relationships",
    "href": "functions.html#testing-bivariate-relationships",
    "title": "5  Useful functions",
    "section": "5.6 Testing bivariate relationships",
    "text": "5.6 Testing bivariate relationships\n\nt.test()\ncor()"
  },
  {
    "objectID": "functions.html#modelling",
    "href": "functions.html#modelling",
    "title": "5  Useful functions",
    "section": "5.7 Modelling",
    "text": "5.7 Modelling\n\nlm()\nbroom::tidy()\nbroom::glance()\nbroom::augment()"
  },
  {
    "objectID": "03_dataviz.html#bad-viz",
    "href": "03_dataviz.html#bad-viz",
    "title": "4  Data vizualisation",
    "section": "4.1 Bad viz",
    "text": "4.1 Bad viz\n\nHere details on what makes a good or bad vizualisation.\nhttp://albertocairo.com/\nhttps://visionscarto.net/hieroglyphes-isotype\nhttps://visionscarto.net/la-semiologie-graphique-a-50-ans\nForget about pie charts : One of the first graph that comes in our mind when we think about data vizualisation are pie chart (or camemberts as we say in french). If you have already done that once in your life, I warn you that it will not happen again.\n\nDo not use double axes\n\nAccording to briatte slides : use facets/use annotations\n\nIf you want to learn more about graphs, I recommand you to read this and this. Healy, Winston Chang : different reasons why graphs might be bad or not (why is this not in the doc anymore, look back at healy, differentces between perception, information etc. )\nhttps://medium.com/(fneves/stop-using-those-ugly-pie-charts-962ac70beb41?) https://www.data-to-viz.com/caveat/pie.html"
  },
  {
    "objectID": "03_dataviz.html#the-grammar-of-graphics",
    "href": "03_dataviz.html#the-grammar-of-graphics",
    "title": "4  Data vizualisation",
    "section": "4.2 The grammar of graphics",
    "text": "4.2 The grammar of graphics\nThere are three main ploting systems available for creating graphs in R. Base R provides functions such as plot(), hist() or boxplot() (you can also explore the lattice package). However, in this session, we will focus on a widely popular package called ggplot. It is a component of the tidyverse, so there is no need to install or load it separately if the tidyverse package is already loaded.\nThe “gg” in ggplot represents the “grammar of graphics” (Wilkinson 2012). Graphs are constructed by adding various layers to a basic graph, allowing for progressively more complex modifications such as adjusting the title or adding annotations.\nTo do a graph in ggplot, you need at least three things : a dataframe, aestethics and a geometry.\n\nFirst the data : a dataframe, in a tidy format : observations as rows and variables as columns\nAesthetics : axe des x, axe des y, couleur, forme des points, type de ligne\n\nYou need to add + between each element :syntaxe additive et pas des pipes ! The geometry allows you to specify how you want to represent your data : geom_point(), geom_line().\nNot always easy to decide which graph is best at representing the information we want. You can have a look on the data to viz website or the R graph gallery which can help you doing this.\nThis might be quite abstract at this point but you will see how it works in a few minutes. But before to show you how to do graphs, just a few recommandations on what you should not do. According to Healy, graphs may be bad for three main reasons : aesthethic, substantive and perceptual.\nDifferent layes in ggplot :\n\ndata\naesthethics mapping\ngeom\nfacets\nstatistics\ncoordinates\nthemes"
  },
  {
    "objectID": "01_getting_started.html#a-motivation-for-this-class-what-is-programming-and-why-would-we-need-it-in-social-sciences",
    "href": "01_getting_started.html#a-motivation-for-this-class-what-is-programming-and-why-would-we-need-it-in-social-sciences",
    "title": "Introduction",
    "section": "A motivation for this class : what is programming and why would we need it in social sciences",
    "text": "A motivation for this class : what is programming and why would we need it in social sciences\nBefore we start, I think it is necessary to give a few words about why we are doing this. Learning Rstudio means learn how to code, how to program : why should we do that as social scientists ? Why would we even bother to learn that stuff that looks complicated ? Why do not just used excel to do some calculations ? R is a programming language, programming means giving instrucgtions to a computer in order to realize some tasks. And we use a software to do this because it is easier.\nYou might be thinking, “I’ve already learned Excel and can perform some data analysis tasks with it. Why should I bother learning to code in a seemingly complex language?”, SPSS or SAS, STATA\nHowever, this has the disadvantage of having less comprehensive documentation compared to other languages like STATA.\nTo analyze quantitative data, we need a computer to help us to do some tasks such as accessing, manipulating data, vizualizing it and modelling it. To ask our computer to do it, we usaully rely on a software and there are of different kind in the market. You probably all know excel or you would have heard of STATA, SPSS or SAS. However, the trend is to use R and has becoming more and more popular.\nI really want to make a case for why this class is very important.\n\nWhy programming and what is could be useful for :\nData manipulation\nBut also lot of fancier stuff that are more and more used in social sciences (web scraping, social networks analysis, maps, text analysis, image analysis, machine learning)\nThis class is just intro so we will not cover all of these but I can give you more ressources if you want to learn and at the end of this class, you should be definitely able to go in depth by yourself in some of these topics.\n\n\nReproducibility\nReproducibility is that the same analysis can be exactly redone given the code and the data. First, your future you. Second other people. See Gelman 2016 as well.\nReproducibility or Replicatioon ?\nAnother reason why it is useful doing this is reproducibility. You might have heard of the “replication crisis” in science. During the last decades, people have tried to replicate analysis made by others and usually they did not succeed.\nThis has led most journals to condition publication upon you provide code, data and that they are able to reproduce your results. Nowadays, if you want to publish in a journal using quantitative data, almost all of them will ask your for your replication code.\n\n\n\n\n\nThis is important because, it gives more transparency of the decisions you make as a quantitative researcher. Quantitative analysis requires a lot of choices on how you choose your variables, how you recode them, you compute summary, which observations you keep and you discard. By having everything in a code that everyone can look at is a good practice. Coding helps you reflect on what you do with the data. Looking at the code of others make you more critical of their research.\n\n\nComputational social sciences\nRise of computational social sciences\n\n\nValuable skills on the job market\n\nLearning skills that will be really valuable on the job market (academia, industry, public administration) : many position that requires getting data, sumamrizing it and analyzing it.\n\nIf you think about\nEven if you want to pursue a career in an other sector, “data science” skills are also really valuable and trendy.\n\n\n\n\n\n\nMore and more jobs require to analyze data, and there are more and more data due to digitalization.\n\nIn you want to continue in academia, quantitative skills and programming are highly valuable and pre-requisite for many positions. Journals also more and more ask for replications code when you want to publish an article in order that the other could replicate your findings. In political science, R is more and more the dominant language.\n\n\nProgramming as a qualitative researcher ?\nThis class teaches you how to use programming to analyze data in a quantitative fashion. Programming is usually associated with quantitative research in social sciences because it is useful to analyze a large number of data. If you are a more qualitative researcher, you might be frightened by all of this, why you would learn all of that stuff and I need to convince you that it is still useful to learn for different reasons. Yet, here a few incentives for people who may qualify themselves are more qualtitative research to invest some resources in learning this.\nAt the end, the beauty of programming is automation and you can also automate some tasks in qualitative research.\n\nFirst, Let yourself be surprised. Many people start this master having no intention at all to do quantitative analysis and eventually they do\nCollecting data and storing data: web scraping, eg : online ethnography of a social media but you would still need to collect that data and you will quickly learn that copy and post social media post in a word file is not the way to go.\nDescribe data, contextualize : you might have access to many documents, interviews but have some trends\nFormatting data : programmation :\n\n\nimage to text\nspeech to text\n\n\nThen, even if the core of your research is qualitative, you could be more convincing by adding some descriptive graphs to depict the broader universe of your topic, do some descriptive statistics to contextualize your interviews and so on., you could suprisingly discover a dataset that is super useful for you research and have tha ability yo analyze it even if at first sight you would not have do so\nIf you want to analyze reports, text qualitatively, programming can however be a useful way to automate their collection online and to efficiently store them. You could also have a inductive automated text analysis of your document before going through a careful reading of them.\nFinally, recent advances in AI have made it possible, with just a few lines of code, to have very high quality automatic audio-to-text transcriptions for interviews. A knowledge of programming makes this type of algorithm easy to use (have a look on this tuto with python : )\n\n\n\nWhy R ?\n\nIt s free, open source, built by a community of people, people adapt the language to new tools\nSpecialized in statistics\nBut high learning curve : learning R is quite difficult at the begining. And the best thing to do to learn it is to have a goal.\nWhy not Python ? Python also highly valuable skills and more popular in industry in general. Moreover, if you are interested in recent machine learning techniques and text analysis, everything that is developed is in Python. Python is more general, more flexible because less abstraction"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wilkinson, Leland. 2012. The Grammar of Graphics. Springer."
  },
  {
    "objectID": "01_getting_started.html#functions",
    "href": "01_getting_started.html#functions",
    "title": "2  Introduction",
    "section": "2.7 Functions",
    "text": "2.7 Functions\n\nhey <- c(1, 2, 3)\nsum(hey)\n\n[1] 6\n\nmean(this_is_a_vector) # This is an error\n\nWarning in mean.default(this_is_a_vector): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nHEre we get warning messages\nWhen you write code, you want to annotate your code for the others to understand or you future you. You wan use the # and say : this is a comment. You can try to run this and you wont have anything.\nHow to index vectors : get a specific value\n\nBase R and the tidyverse\n\nvector are sequences of things\n\nDo some vocab definitions ? What is a function ? What is a vector ?\nObjects and assignments in R <- However, we use scripts in R\nWhat is a function, what is an argument\nLearn how to use a script to compute different things ### Indexation\n\nYou can access specific elements of vectors by indexing, which is performed by using square brackets [].\n\npoliticians <-c(\"Macron\", \"Schultz\", \"Biden\", \"Sanchez\", \"Meloni\", \"Sunak\")\n\npoliticians[3]\n\n[1] \"Biden\"\n\npoliticians[-3]\n\n[1] \"Macron\"  \"Schultz\" \"Sanchez\" \"Meloni\"  \"Sunak\"  \n\npoliticians[c(1,5)]\n\n[1] \"Macron\" \"Meloni\"\n\npoliticians[1:3]\n\n[1] \"Macron\"  \"Schultz\" \"Biden\"  \n\npoliticians[politicians == \"Macron\"]\n\n[1] \"Macron\"\n\npoliticians[politicians != \"Macron\"]\n\n[1] \"Schultz\" \"Biden\"   \"Sanchez\" \"Meloni\"  \"Sunak\"  \n\npoliticians[politicians %in% c(\"Macron\", \"Meloni\")]\n\n[1] \"Macron\" \"Meloni\"\n\n\n\n2.7.1 Attributes\nR objects have attributes\n\nclass(\"a cat\")\n\n[1] \"character\"\n\nclass(1)\n\n[1] \"numeric\"\n\n\"a cat\" |> attr(\"class\")\n\nNULL"
  },
  {
    "objectID": "index.html#introduction-to-r-and-setup",
    "href": "index.html#introduction-to-r-and-setup",
    "title": "Introduction to R",
    "section": "1.1 Introduction to R and setup",
    "text": "1.1 Introduction to R and setup"
  },
  {
    "objectID": "01_getting_started.html#prerequisites",
    "href": "01_getting_started.html#prerequisites",
    "title": "Introduction",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis class requires no experience in programming and it is for complete beginners to accompany you to use R. Some of you might have already learnt it and you will be faster than the others, do not hesitate if you want extra."
  },
  {
    "objectID": "session0/00_getting.html#install-r",
    "href": "session0/00_getting.html#install-r",
    "title": "Setting up R and Rstudio",
    "section": "Install R",
    "text": "Install R\nYou can install R from CRAN (The comprehensive R Archive Network). On the site, you will ll find links to download the version of R you need for your operating system (Windows, Mac or Linux). Then click to download the latest version. Once the download is complete, you need to execute the installer."
  },
  {
    "objectID": "session0/00_getting.html#install-rstudio",
    "href": "session0/00_getting.html#install-rstudio",
    "title": "Setting up R and Rstudio",
    "section": "Install Rstudio",
    "text": "Install Rstudio\nOnce R is set up, you can install Rstudio. For this, go on this webpage, download Rstudio and follow the instructions."
  },
  {
    "objectID": "session0/00_getting.html#set-preferences",
    "href": "session0/00_getting.html#set-preferences",
    "title": "Setting up R and Rstudio",
    "section": "Set preferences",
    "text": "Set preferences\nRstudio has a whole series of default settings that are worth changing to adopt best practices. Please do the following:\n\nTools > Global Options > RGeneral : here save workspace to never.\nDepending on your taste, you can also change the appearance of Rstudio but that depends on you"
  },
  {
    "objectID": "session0/00_getting.html#installing-package",
    "href": "session0/00_getting.html#installing-package",
    "title": "Setting up R and Rstudio",
    "section": "Installing package",
    "text": "Installing package\nTo make sur everything works, try to install a package by typing “install.package(”tidyverse)” inside the bottom left pane and click enter. It should take a moment. But if at the end no error, you are ready to go. If you have some errors, please write me an email."
  },
  {
    "objectID": "session0/00_getting.html#opening-r-studio-set-preferences-and-look-if-everything-works",
    "href": "session0/00_getting.html#opening-r-studio-set-preferences-and-look-if-everything-works",
    "title": "Setting up R and Rstudio",
    "section": "Opening R studio, set preferences and look if everything works",
    "text": "Opening R studio, set preferences and look if everything works"
  },
  {
    "objectID": "session0/00_getting.html#set-preferences-and-check-if-everything-works",
    "href": "session0/00_getting.html#set-preferences-and-check-if-everything-works",
    "title": "Setting up R and Rstudio",
    "section": "Set preferences and check if everything works",
    "text": "Set preferences and check if everything works\nThen open Rstudio. If it worked, you should see something similar to the screenshot below\n\nRstudio has some default settings that are worth changing to adopt best practices. Please do the following\n\nTools /Global options/RGeneral : Save workspace to never and uncheck the box Restore .Rdata into workspace at startup.\n\nWhile R provides a series of basic commands for data manipulation, many of the functionalities we will use come from packages that need to be installed and loaded via RStudio. The most well-known package we will use is called “tidyverse.” To check if your installation is successful and you are ready to start the course, copy-paste the following code into the console at the bottom left of your screen. It might take a few minutes, and at the end, you should see the same message as the one below. In that case, you are ready to go. If not, please let me know.\n\nif (!require(tidyverse)) {install.packages(\"tidyverse\")}\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
  },
  {
    "objectID": "session0/00_getting.html#ressources",
    "href": "session0/00_getting.html#ressources",
    "title": "Setting up R and Rstudio",
    "section": "Ressources",
    "text": "Ressources"
  }
]