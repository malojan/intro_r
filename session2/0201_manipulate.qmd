

# Manipulating data

At this point, you are now able to import a data file into Rstudio and quickly explore the structure of the dataset, which is usually the first step in any analysis. If the dataset is well-structured, we then need to carry out a very important operation, which we'll see how to do in R: manipulate the data to obtain the information we want. In many cases, we're not interested in the whole dataset; we want to select specific variables, analyze only certain groups and see how these variables vary according to these groups.

With R, there are several ways to perform these operations. Firstly, you can use R's base functions, without having to load a specific package. An alternative approach is based on the `tidyverse`, the package suite developed by [Hadley Wickham](https://en.wikipedia.org/wiki/Hadley_Wickham) with a special syntax. Here, we'll concentrate on the `tidyverse` functions, which I feel are easier and more intuitive to use.

The `tidyverse` relies extensively on what is called "the pipe" : `|>`. You will quickly understand what the pipe is, we use it to chain instructions just as in a recipe. Depending on the version of R, you might also use/see this `%>%`.

## Introduction to dplyr functions

To manipulate data, we will use a package from the tidyverse called `dplyr`, comprising a comprehensive suite of exceptionally useful functions. To familiarize ourselves with its usage, we will explore the [Quality of Government Environmental Indicators](gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset) dataset. To do this, we will need first to load the tidyverse and import the data.

```{r}
# Load the tidyverse

library(tidyverse) 

qog <- haven::read_dta("data/qog_env.dta") 
```

### `count()`

From Exercise 1, we saw that the qog dataset has a country-year structure. For each country, we have a series of indicators with one value per year. the `qog` dataset has a `year` variable and a `cname` variable (for country).

```{r}

qog |> # This is a pipe
  count(year)

table(qog$year) # Alternative way to do it but the result is less nice

qog |> 
  count(year, cname) # Only one country-year observation
```

### `filter()` observations

We may want to use only a subset of countries and get a smaller versions of the dataset. And the tidyverse has one for this, which is called `filter()` We want to select specific rows/observations of the dataset based on a specific conditions. To filter, we will use extensively boolean operators.

| Operator | Description           |
|----------|-----------------------|
| `==`     | equal                 |
| `!=`     | not equal             |
| `<`      | less than             |
| `<=`     | less than or equal    |
| `>`      | greater than          |
| `>=`     | greater than or equal |
| `&`      | and                   |
| `|`      | or                    |
| `!`      | not                   |
| `%in%`   | in the set            |

For instance, I might be only interested in environmental indicators for France. In that case I could filter the whole dataset with only the observations that has France as country variable.

```{r}
qog |> filter(cname %in% c("France", "Afghanistan"))

qog |> 
  filter(cname != "France") 
```

Here, see that the tidyverse functions are a bit intuitive that what you could do directly with R base functions. To do the same, here an example of what we would have done :

```{r}
qog[qog$cname %in% c("France"), ]
```

You could also filter by all of the countries that are NOT France and count how many observations we have for each.

```{r}
qog |> 
  # Keep only countries that are not France
  filter(cname != "France") |> 
  # Count the number of observations for each country
  count(cname, sort = TRUE) # Use Sort = TRUE if you want to sort the results
```

Or you could try with a few countries. In that case, you can use `%in%`.

```{r}
qog |>
  filter(
    cname %in% c(
      "France",
      "Norway",
      "Spain",
      "Denmark")) |> 
  count(cname)
```

But we also want to store the data to manipulate it and so it is easier to create an object.

```{r}

countries <- c("France", "Norway", "Spain")

(qog_subset <- qog |>
   # Keep only the following countries
  filter(
    cname %in% c(
      "France",
      "Norway",
      "Spain",
      "Denmark",
      "Netherlands",
      "Poland",
      "Russia",
      "Saudi Arabia",
      "India"
    ),
    # Keep only the observations that are after 1990
    year > 1990
  ))
```

## Subset rows with `slice()`

You can also subset rows by their positions using `slice()`.

```{r}

qog_subset |> slice(5:7) # Subset only rows 5 to 7
qog_subset |> slice(-1) # Remove the first row

qog_slice <- qog_subset |> slice_max(year, n = 5) # Get the n max results of a variable


qog_subset |> slice_min(year, n = 3) # Get the n min results of a variable

view(qog_subset)
```

## `select()` variables

While `filter()` is useful for keeping only certain groups of rows, `select()` is used, as its name suggests, to select certain variables (columns) from our dataframe.

Let's say I'm interested in CO2 emissions per capita, their overall level and how they vary over time and by country. For this, I would need only three variables that are present in the dataset: `year`, `cname` and the variable `wdi_co2` which comes from the [World Bank's World Development Indicators](https://databank.worldbank.org/source/world-development-indicators). To do this, I use `select()` and just specify which variables of the dataset I want to select.

```{r}
qog_subset |> 
  select(cname, year,  wdi_co2)
```

The `select()` functions offer a lot of possibilities to select variable based on certain patterns by adding functions inside such as `starts_with()`, `ends_with()`, `contains()`. You can learn more by typing `?select`.

```{r}
colnames(qog_subset)

qog_wdi <- qog_subset |> 
  # Select the country, the year and every variable that starts with wdi. 
  select(cname, year, starts_with("wdi"))

# Look at which columns we have in our dataset

qog_wdi |> colnames()

# Select all of the variable that do not starts with wdi

qog_wdi |> select(-starts_with("wdi")) |> colnames()

# Select column by position (from 1 to 5)

qog_wdi |> select(1:5) |> colnames()

qog_wdi |> colnames()

qog_wdi |> 
  # Select only the variables that have numeric as type
  select_if(is.character) |> 
  # Look at which columns we have in our dataset
  colnames()
```

## Change column names with `rename()`

Occasionally, you may encounter datasets with columns named in a non-meaningful manner, such as v5, x45, or Q234, often representing variable identifiers from surveys. To enhance the understanding of the variables' meanings, it can prove beneficial to rename these columns using the rename() function. In our current dataset, the variable names are already quite informative. However, for the purpose of this illustration, let's rename the 'cname' variable as 'country', offering a more explicit label.

```{r}
qog_renamed <- qog_wdi |> 
  # Rename the variable cname as country
  rename(country = cname) 


qog_renamed |> 
  colnames()

# More complex ! 

qog_renamed <-  qog_renamed |> 
  # Remove wdi_ from all of the variables names that starts with wdi
  rename_with(~ str_remove(.x, "wdi_"), starts_with("wdi")) 

qog_renamed |> colnames()
```

## Calculating statistics by group with `group_by()` and `summarise()`

To compute a first set of descriptive statistics, we could look at the central indicators of the co2 emissions variable (`wdi_co2`).

```{r}

mean(qog_wdi$wdi_co2, na.rm = TRUE) # Compute the mean
median(qog_wdi$wdi_co2, na.rm = TRUE) # Compute the median
sd(qog_wdi$wdi_co2, na.rm = TRUE) # Compute the standard deviation
quantile(qog_wdi$wdi_co2, na.rm = T) # Compute the quantiles
```

However, we are often interested in how these indicators vary across groups such as country or year. To do so, use the `summarise()` function in R that allows you to compute new variables by groups. To choose grouping variable, we use first `group_by()` where we specify for which group we want to compute something. Here I use this function to compute the mean, the median, the standard deviation and the first and third quartile of co2 emissions per capita for each country. This gives us a new tibble with all of the summary information.

```{r}
(qog_stats <- qog_wdi |> 
   group_by(cname) |> 
  summarise(mean_co2 = mean(wdi_co2, na.rm = TRUE), 
            median_co2 = median(wdi_co2, na.rm = TRUE),
            sd_co2 = sd(wdi_co2, na.rm = TRUE),
            q1 = quantile(wdi_co2, 0.25, na.rm = TRUE),
            q3 = quantile(wdi_co2, 0.25, na.rm = TRUE)))

```

To get nice tables when you render your quarto document, you can use the `knitr::kable()` function.

```{r}
#| output: asis 

qog_stats |> knitr::kable()
```

It is also possible to sort the results to gain a clearer idea of which countries have the highest average CO2 emissions per capita. To achieve this, we utilize the `arrange()` function, specifying the variable by which we intend to sort. By doing so, we observe that, on average, Saudi Arabia, Russia, and the Netherlands possess the highest carbon footprint per capita among the selected countries.

```{r}
qog_stats |> 
  arrange(-median_co2)

qog_stats |> 
  arrange(mean_co2)
```

Now I want to know when emissions per capita levels were the lowest in Saudia Arabia. I can filter only this country, select the variables of interest and sort the dataframe. We observe that the CO2 emissions per capita were at their minimum towards the late 1990s (which is not good).

```{r}
qog_wdi |> 
  filter(cname == "Saudi Arabia") |> 
  select(cname, year, wdi_co2) |> 
  arrange(wdi_co2)
```

We can also compute descriptive statistics on several variables at the same time with the `across()` function.

```{r}
qog_growth <- qog_wdi |> 
  group_by(cname) |> 
  summarise(across(c(wdi_co2, wdi_fossil),~ mean(.x, na.rm = T)))

qog_growth
```

### Mutate

We can also create new variables based on other ones with `mutate()`. Let's say I want to compute the growth rate of co2 emissions per capita every year. For this, I will use `mutate()` to create new variables.

```{r}
qog_wdi |> 
  select(cname, year, wdi_fossil) |> 
  mutate(dataset = "QOG dataset")
```

To compute the growth rate, we need for each year the emissions per capita of that year and those from the previous year, which I access with `lag()`.

```{r}

qog_wdi <- qog_wdi |>
  select(cname, year, wdi_co2) |> 
  mutate(co2_lag = lag(wdi_co2),
        co2_growth = (wdi_co2 - co2_lag) / co2_lag*100)
```

## Recode values with `case_when`

`Mutate()` is also widely used to recode variable. Here we create a new `trajectory` variable and we use `case_when()` to recode whether there co2_emissions are growing or not for a given year.

```{r}
qog_wdi <- qog_wdi |> 
  mutate(
    trajectory = case_when(
      co2_growth > 0 ~ "Bad",
      co2_growth < 0 ~ "Good"
    )
  )

view(qog_wdi)

qog_wdi |> 
  count(trajectory)
```

## Small exercice

Find the countries that are the most affected by natural disasters (hint : look at the variables starting with `emdat`)
